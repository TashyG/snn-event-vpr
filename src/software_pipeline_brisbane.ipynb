{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from __future__ import annotations\n",
    "from time import time\n",
    "from BrisbaneVPRDatasetTime import BrisbaneVPRDatasetTime\n",
    "from VPRNetwork import VPRNetwork\n",
    "from plotting import plot_confusion_matrix, plot_match_images, plot_gps\n",
    "from constants import brisbane_event_traverses, brisbane_event_traverses_aliases\n",
    "from utils import get_short_traverse_name\n",
    "\n",
    "import os, sys\n",
    "import torch\n",
    "from torch.utils.data import DataLoader\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib import animation\n",
    "from scipy import signal\n",
    "from datetime import datetime\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "import lava.lib.dl.slayer as slayer\n",
    "from lava.lib.dl.slayer.classifier import Rate\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training settings\n",
    "from cgi import test\n",
    "\n",
    "epochs = 60\n",
    "batch_size = 10\n",
    "\n",
    "# Network settings\n",
    "input_size = 34\n",
    "threshold = 1.0\n",
    "\n",
    "# Data settings\n",
    "train_traverse = brisbane_event_traverses[0]\n",
    "test_traverse = brisbane_event_traverses[3]\n",
    "train_name = brisbane_event_traverses_aliases[get_short_traverse_name(train_traverse)]\n",
    "test_name = brisbane_event_traverses_aliases[get_short_traverse_name(test_traverse)]\n",
    "num_places = 77\n",
    "start_dist = 200\n",
    "place_gap = 100 #164/num_places # The streams run for approximately 164 seconds \n",
    "samples_per_sec = 1000\n",
    "place_duration = 2\n",
    "max_spikes = None\n",
    "\n",
    "match_tolerance = 0\n",
    "\n",
    "# Sequencer settings\n",
    "sequence_length = 3\n",
    "\n",
    "# Plot settings\n",
    "redo_plot = False\n",
    "vmin = 0\n",
    "vmax = 0.07\n",
    "\n",
    "def transpose( matrix):\n",
    "    if len(matrix) == 0:\n",
    "        return []\n",
    "    return [[matrix[i][j] for i in range(len(matrix))] for j in range(len(matrix[0]))]\n",
    "\n",
    "\n",
    "# Make a folder for the trained network\n",
    "trained_folder = 'Trained'\n",
    "os.makedirs(trained_folder, exist_ok=True)\n",
    "\n",
    "# Use GPU\n",
    "print(torch.cuda.is_available())\n",
    "device = torch.device('cuda')\n",
    "\n",
    "#---------------- Create the Network -----------------#\n",
    "\n",
    "# Create the network\n",
    "net = VPRNetwork(input_size, num_places, threshold=threshold).to(device)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the data\n",
    "training_set = BrisbaneVPRDatasetTime(train_traverse, train=True, place_duration = place_duration, place_gap=place_gap, num_places=num_places, start_dist=start_dist,samples_per_sec=samples_per_sec, max_spikes=max_spikes)\n",
    "testing_set  = BrisbaneVPRDatasetTime(test_traverse, train=False, place_duration = place_duration, training_locations=training_set.place_locations, place_gap=place_gap, num_places=num_places, start_dist=start_dist, samples_per_sec=samples_per_sec, max_spikes=max_spikes)\n",
    "            \n",
    "train_loader = DataLoader(dataset=training_set, batch_size=batch_size, shuffle=True)\n",
    "test_loader  = DataLoader(dataset=testing_set , batch_size=batch_size, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "time_stamp = datetime.now().strftime('%Y-%m-%d_%H-%M-%S')\n",
    "results_path = \"./../results/\" + time_stamp\n",
    "os.mkdir(results_path)\n",
    "\n",
    "\n",
    "# Define an optimiser \n",
    "optimizer = torch.optim.Adam(net.parameters(), lr=0.001)\n",
    "\n",
    "# Training the network\n",
    "error = slayer.loss.SpikeRate(true_rate=0.2, false_rate=0.03, reduction='sum').to(device)\n",
    "\n",
    "# Create a training assistant object\n",
    "stats = slayer.utils.LearningStats()\n",
    "assistant = slayer.utils.Assistant(net, error, optimizer, stats, classifier=slayer.classifier.Rate.predict)\n",
    "\n",
    "\n",
    "if redo_plot:\n",
    "    for i, (input, label) in enumerate(train_loader): # training loop\n",
    "        output = assistant.train(input, label)\n",
    "\n",
    "else: \n",
    "    for epoch in range(epochs):\n",
    "\n",
    "        for i, (input, label) in enumerate(train_loader): # training loop\n",
    "            output = assistant.train(input, label)\n",
    "        print(f'\\r[Epoch {epoch:2d}/{epochs}] {stats}', end='')\n",
    "\n",
    "        for i, (input, label) in enumerate(test_loader): # training loop\n",
    "            output = assistant.test(input, label)\n",
    "        print(f'\\r[Epoch {epoch:2d}/{epochs}] {stats}', end='')\n",
    "\n",
    "        if epoch%20 == 19: # cleanup display\n",
    "            print('\\r', ' '*len(f'\\r[Epoch {epoch:2d}/{epochs}] {stats}'))\n",
    "            stats_str = str(stats).replace(\"| \", \"\\n\")\n",
    "            print(f'[Epoch {epoch:2d}/{epochs}]\\n{stats_str}')\n",
    "\n",
    "        if stats.testing.best_accuracy:\n",
    "            torch.save(net.state_dict(), results_path + '/network.pt')\n",
    "        stats.update()\n",
    "        stats.save(results_path + '/')\n",
    "        net.grad_flow(results_path + '/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import the best network during training \n",
    "net.load_state_dict(torch.load(results_path + '/network.pt'))\n",
    "net.export_hdf5(results_path + '/network.net')\n",
    "\n",
    "# Get the output for the input to each place\n",
    "test_loader2  = DataLoader(dataset=testing_set , batch_size=batch_size, shuffle=False)\n",
    "rate = []\n",
    "labels = []\n",
    "for i, (input, label) in enumerate(test_loader2):\n",
    "    output = net(input.to(device)) # Get network output\n",
    "    #guesses = assistant.classifier(output).cpu().data.numpy() # get the predictions \n",
    "    rate.extend(Rate.confidence(output).cpu().data.numpy()) # Get the firing rates for each place \n",
    "    labels.extend(label.cpu().data.numpy()) # Get place labels\n",
    "\n",
    "#print(rate)\n",
    "# # Get rates in percentages of total\n",
    "# for i in range(num_places):\n",
    "#     sum = np.sum(rate[i])\n",
    "#     if sum != 0:\n",
    "#         rate[i] = np.divide(rate[i],sum)\n",
    "\n",
    "# Make confusion matrix annotations\n",
    "accuracy = 0\n",
    "matches = []\n",
    "annotations = [['' for i in range(num_places)] for j in range(num_places)]\n",
    "for qryIndex in range(num_places):\n",
    "    max_idx = np.argmax(rate[qryIndex])\n",
    "    matches.append(max_idx)\n",
    "    annotations[max_idx][qryIndex] = 'x'\n",
    "    if abs(max_idx - qryIndex) <= match_tolerance:\n",
    "        accuracy += 1\n",
    "\n",
    "\n",
    "#--------------- Apply a sequencer ------------------#\n",
    "I = np.identity(sequence_length)\n",
    "conv = signal.convolve2d(rate, I, mode='same')/sequence_length\n",
    "print(np.shape(conv))\n",
    "\n",
    "\n",
    "# Make confusion matrix annotations\n",
    "accuracy_s = 0\n",
    "matches_with_seq = []\n",
    "annotations_s = [['' for i in range(num_places)] for j in range(num_places)]\n",
    "for qryIndex in range(num_places):\n",
    "    max_idx = np.argmax(conv[qryIndex])\n",
    "    matches_with_seq.append(max_idx)\n",
    "    annotations_s[max_idx][qryIndex] = 'x'\n",
    "    if abs(max_idx - qryIndex) <= match_tolerance:\n",
    "        accuracy_s += 1\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#--------------- Save Results ------------------#\n",
    "\n",
    "# Make new folder for results\n",
    "from tracemalloc import start\n",
    "from plotting import plot_gps\n",
    "\n",
    "temp_rate = torch.tensor(rate).reshape(torch.tensor(rate).shape[0], -1)\n",
    "temp_conv = torch.tensor(conv).reshape(torch.tensor(conv).shape[0], -1)\n",
    "confidence = temp_rate / (torch.sum(temp_rate, dim=1, keepdim=True) + 1e-6)\n",
    "confidence_seq = temp_conv / (torch.sum(temp_conv, dim=1, keepdim=True) + 1e-6)\n",
    "\n",
    "\n",
    "# Save query and match images \n",
    "images_path = results_path + \"/matched_images\"\n",
    "images_path_seq = results_path + \"/matched_images_seq\"\n",
    "os.mkdir(images_path)\n",
    "os.mkdir(images_path_seq)\n",
    "\n",
    "#print('help')\n",
    "plot_match_images(images_path + \"/\", matches, training_set.place_images, testing_set.place_images)\n",
    "plot_match_images(images_path_seq + \"/\", matches_with_seq, training_set.place_images, testing_set.place_images)\n",
    "\n",
    "# Save the confusion matrices\n",
    "confusion_path = results_path + \"/confusion_matrices\"\n",
    "os.mkdir(confusion_path)\n",
    "confidence = transpose(confidence)\n",
    "confidence_seq = transpose(confidence_seq)\n",
    "output_path = confusion_path + \"/confusion_matrix\" \n",
    "output_path_s = confusion_path + \"/confusion_matrix_seq\" \n",
    "plot_confusion_matrix(confidence, labels, annotations, output_path, vmin, vmax)\n",
    "plot_confusion_matrix(confidence_seq, labels, annotations_s, output_path_s, vmin, vmax)\n",
    "\n",
    "# Save GPS map'\n",
    "gps_path = results_path + \"/gps_locations\"\n",
    "plot_gps(gps_path, training_set.place_locations, testing_set.place_locations)\n",
    "\n",
    "# Save test settings and accuracy\n",
    "accuracy = accuracy/num_places\n",
    "accuracy_s = accuracy_s/num_places\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "log_path = results_path + \"/log.txt\"\n",
    "log_string  = \"\"\"\n",
    "---- DATA SETTINGS ---- \n",
    "Training datasets = {}\n",
    "Testing datasets = {} \n",
    "# Places = {}\n",
    "Start dist = {} [m]\n",
    "Place gap = {} [m]\n",
    "Place duration = {} [s]\n",
    "Samples per second = {} \n",
    "Max spikes per sample = {}\n",
    "---- NETWORK SETTINGS ---- \n",
    "Input size = {}x{} \n",
    "Threshold = {}\n",
    "---- TRAINING SETTINGS ---- \n",
    "Epochs = {}\n",
    "Batch size = {}\n",
    "---- SEQUENCER SETTINGS ----\n",
    "Sequence lengtth = {} \n",
    "---- RESULTS ----\n",
    "Match tolerance = {}\n",
    "Accuracy = {}\n",
    "Accuracy (sequencer) = {}\n",
    "\"\"\".format(train_name,test_name,num_places,start_dist,place_gap,place_duration,\n",
    "                samples_per_sec,max_spikes,input_size,input_size,threshold,epochs,\n",
    "                batch_size,sequence_length,match_tolerance,accuracy,accuracy_s)\n",
    "f = open(log_path,'w')\n",
    "f.write(log_string)\n",
    "f.close()\n",
    "\n",
    "print(\"The accuracy of the network is: \" + str(accuracy))\n",
    "print(\"The accuracy with a sequencer is: \" + str(accuracy_s))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.4 ('lavaenv')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "63e713066215dbc07efbeb034515a5b964b6ad27977c03151c829f7f04a8001d"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
