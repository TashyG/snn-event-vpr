{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "%%% Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from __future__ import annotations\n",
    "from time import time\n",
    "from BrisbaneVPRDatasetSpeed import BrisbaneVPRDatasetSpeed\n",
    "from VPRNetwork import VPRNetwork\n",
    "from plotting import plot_confusion_matrix, plot_match_images, plot_gps\n",
    "from constants import brisbane_event_traverses, brisbane_event_traverses_aliases\n",
    "from utils import get_short_traverse_name\n",
    "\n",
    "import os, sys\n",
    "import torch\n",
    "from torch.utils.data import DataLoader\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib import animation\n",
    "from scipy import signal\n",
    "from datetime import datetime\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "import lava.lib.dl.slayer as slayer\n",
    "from lava.lib.dl.slayer.classifier import Rate\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n"
     ]
    }
   ],
   "source": [
    "# Training settings\n",
    "from cgi import test\n",
    "\n",
    "\n",
    "epochs = 50\n",
    "batch_size = 10\n",
    "\n",
    "# Network settings\n",
    "input_size = 34\n",
    "threshold = 1.0\n",
    "\n",
    "# Data settings\n",
    "train_traverse = brisbane_event_traverses[0]\n",
    "test_traverse = brisbane_event_traverses[3]\n",
    "train_name = brisbane_event_traverses_aliases[get_short_traverse_name(train_traverse)]\n",
    "test_name = brisbane_event_traverses_aliases[get_short_traverse_name(test_traverse)]\n",
    "num_places = 45\n",
    "start_dist = 200\n",
    "place_gap = 100 #164/num_places # The streams run for approximately 164 seconds \n",
    "samples_per_sec = 1000\n",
    "place_length = 27\n",
    "max_spikes = None\n",
    "\n",
    "# Sequencer settings\n",
    "sequence_length = 3\n",
    "\n",
    "# Plot settings\n",
    "redo_plot = False\n",
    "vmin = 0\n",
    "vmax = 0.05\n",
    "\n",
    "def transpose( matrix):\n",
    "    if len(matrix) == 0:\n",
    "        return []\n",
    "    return [[matrix[i][j] for i in range(len(matrix))] for j in range(len(matrix[0]))]\n",
    "\n",
    "\n",
    "# Make a folder for the trained network\n",
    "trained_folder = 'Trained'\n",
    "os.makedirs(trained_folder, exist_ok=True)\n",
    "\n",
    "# Use GPU\n",
    "print(torch.cuda.is_available())\n",
    "device = torch.device('cuda')\n",
    "\n",
    "#---------------- Create the Network -----------------#\n",
    "\n",
    "# Create the network\n",
    "net = VPRNetwork(input_size, num_places, threshold=threshold).to(device)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading training event streams ...\n",
      "Adding GPS\n",
      "Duration: 527.16s (which is 3432338 events)\n",
      "Distance: 6308.49m (which is 3432338 events)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/n10223622/snn-event-vpr/src/BrisbaneVPRDatasetSpeed.py:232: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  chopped_stream['distance'] -= start_distance\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Place: 0\n",
      "Distance: 24.98m (which is 16667 events)\n",
      "Duration: 1.85s (which is 16667 events)\n",
      "Place: 1\n",
      "Distance: 25.00m (which is 12120 events)\n",
      "Duration: 2.28s (which is 12120 events)\n",
      "Place: 2\n",
      "Distance: 24.99m (which is 6352 events)\n",
      "Duration: 2.03s (which is 6352 events)\n",
      "Place: 3\n",
      "Distance: 25.00m (which is 11740 events)\n",
      "Duration: 2.00s (which is 11740 events)\n",
      "Place: 4\n",
      "Distance: 25.00m (which is 16130 events)\n",
      "Duration: 1.95s (which is 16130 events)\n",
      "Place: 5\n",
      "Distance: 25.00m (which is 9752 events)\n",
      "Duration: 1.91s (which is 9752 events)\n",
      "Place: 6\n",
      "Distance: 25.00m (which is 9289 events)\n",
      "Duration: 1.98s (which is 9289 events)\n",
      "Place: 7\n",
      "Distance: 25.00m (which is 21996 events)\n",
      "Duration: 3.31s (which is 21996 events)\n",
      "Place: 8\n",
      "Distance: 25.00m (which is 19061 events)\n",
      "Duration: 1.95s (which is 19061 events)\n",
      "Place: 9\n",
      "Distance: 24.99m (which is 19612 events)\n",
      "Duration: 1.92s (which is 19612 events)\n",
      "Place: 10\n",
      "Distance: 25.00m (which is 17296 events)\n",
      "Duration: 1.70s (which is 17296 events)\n",
      "Place: 11\n",
      "Distance: 25.00m (which is 16085 events)\n",
      "Duration: 1.62s (which is 16085 events)\n",
      "Place: 12\n",
      "Distance: 25.00m (which is 20430 events)\n",
      "Duration: 1.66s (which is 20430 events)\n",
      "Place: 13\n",
      "Distance: 25.00m (which is 28388 events)\n",
      "Duration: 1.66s (which is 28388 events)\n",
      "Place: 14\n",
      "Distance: 25.00m (which is 25958 events)\n",
      "Duration: 1.63s (which is 25958 events)\n",
      "Place: 15\n",
      "Distance: 25.00m (which is 16024 events)\n",
      "Duration: 1.66s (which is 16024 events)\n",
      "Place: 16\n",
      "Distance: 25.00m (which is 13490 events)\n",
      "Duration: 1.90s (which is 13490 events)\n",
      "Place: 17\n",
      "Distance: 24.99m (which is 5424 events)\n",
      "Duration: 1.88s (which is 5424 events)\n",
      "Place: 18\n",
      "Distance: 25.00m (which is 5547 events)\n",
      "Duration: 1.43s (which is 5547 events)\n",
      "Place: 19\n",
      "Distance: 24.99m (which is 4208 events)\n",
      "Duration: 1.46s (which is 4208 events)\n",
      "Place: 20\n",
      "Distance: 24.85m (which is 2110 events)\n",
      "Duration: 1.44s (which is 2110 events)\n",
      "Place: 21\n",
      "Distance: 24.99m (which is 1630 events)\n",
      "Duration: 1.43s (which is 1630 events)\n",
      "Place: 22\n",
      "Distance: 24.98m (which is 1839 events)\n",
      "Duration: 1.56s (which is 1839 events)\n",
      "Place: 23\n",
      "Distance: 24.99m (which is 4826 events)\n",
      "Duration: 1.84s (which is 4826 events)\n",
      "Place: 24\n",
      "Distance: 24.94m (which is 1334 events)\n",
      "Duration: 2.02s (which is 1334 events)\n",
      "Place: 25\n",
      "Distance: 24.99m (which is 6117 events)\n",
      "Duration: 1.61s (which is 6117 events)\n",
      "Place: 26\n",
      "Distance: 24.99m (which is 13220 events)\n",
      "Duration: 1.75s (which is 13220 events)\n",
      "Place: 27\n",
      "Distance: 24.99m (which is 8063 events)\n",
      "Duration: 1.77s (which is 8063 events)\n",
      "Place: 28\n",
      "Distance: 24.99m (which is 12347 events)\n",
      "Duration: 1.66s (which is 12347 events)\n",
      "Place: 29\n",
      "Distance: 25.00m (which is 17036 events)\n",
      "Duration: 1.68s (which is 17036 events)\n",
      "Place: 30\n",
      "Distance: 24.99m (which is 13095 events)\n",
      "Duration: 1.56s (which is 13095 events)\n",
      "Place: 31\n",
      "Distance: 25.00m (which is 23785 events)\n",
      "Duration: 1.59s (which is 23785 events)\n",
      "Place: 32\n",
      "Distance: 24.99m (which is 14712 events)\n",
      "Duration: 1.66s (which is 14712 events)\n",
      "Place: 33\n",
      "Distance: 25.00m (which is 12160 events)\n",
      "Duration: 2.15s (which is 12160 events)\n",
      "Place: 34\n",
      "Distance: 25.00m (which is 10966 events)\n",
      "Duration: 7.30s (which is 10966 events)\n",
      "Place: 35\n",
      "Distance: 25.00m (which is 8988 events)\n",
      "Duration: 2.56s (which is 8988 events)\n",
      "Place: 36\n",
      "Distance: 24.99m (which is 17246 events)\n",
      "Duration: 28.75s (which is 17246 events)\n",
      "Place: 37\n",
      "Distance: 24.99m (which is 5261 events)\n",
      "Duration: 1.83s (which is 5261 events)\n",
      "Place: 38\n",
      "Distance: 24.99m (which is 13611 events)\n",
      "Duration: 1.77s (which is 13611 events)\n",
      "Place: 39\n",
      "Distance: 25.00m (which is 8719 events)\n",
      "Duration: 1.71s (which is 8719 events)\n",
      "Place: 40\n",
      "Distance: 24.99m (which is 21930 events)\n",
      "Duration: 1.65s (which is 21930 events)\n",
      "Place: 41\n",
      "Distance: 25.00m (which is 20236 events)\n",
      "Duration: 1.65s (which is 20236 events)\n",
      "Place: 42\n",
      "Distance: 25.00m (which is 21660 events)\n",
      "Duration: 1.66s (which is 21660 events)\n",
      "Place: 43\n",
      "Distance: 25.00m (which is 10652 events)\n",
      "Duration: 1.71s (which is 10652 events)\n",
      "Place: 44\n",
      "Distance: 25.00m (which is 26042 events)\n",
      "Duration: 1.78s (which is 26042 events)\n",
      "The number of training substreams is: 45\n",
      "Loading testing event streams ...\n",
      "Adding GPS\n",
      "Duration: 660.00s (which is 2919794 events)\n",
      "Distance: 8245.81m (which is 2919794 events)\n",
      "Place: 0\n",
      "Distance: 24.94m (which is 10855 events)\n",
      "Duration: 1.78s (which is 10855 events)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/n10223622/snn-event-vpr/src/BrisbaneVPRDatasetSpeed.py:259: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  chopped_stream['distance'] -= dist_at_start_time\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Place: 1\n",
      "Distance: 25.00m (which is 9285 events)\n",
      "Duration: 2.45s (which is 9285 events)\n",
      "Place: 2\n",
      "Distance: 25.00m (which is 2574 events)\n",
      "Duration: 2.22s (which is 2574 events)\n",
      "Place: 3\n",
      "Distance: 24.98m (which is 3909 events)\n",
      "Duration: 1.97s (which is 3909 events)\n",
      "Place: 4\n",
      "Distance: 25.00m (which is 5725 events)\n",
      "Duration: 1.94s (which is 5725 events)\n",
      "Place: 5\n",
      "Distance: 24.99m (which is 6345 events)\n",
      "Duration: 1.95s (which is 6345 events)\n",
      "Place: 6\n",
      "Distance: 24.99m (which is 6326 events)\n",
      "Duration: 1.82s (which is 6326 events)\n",
      "Place: 7\n",
      "Distance: 24.99m (which is 12790 events)\n",
      "Duration: 3.44s (which is 12790 events)\n",
      "Place: 8\n",
      "Distance: 24.99m (which is 11360 events)\n",
      "Duration: 1.86s (which is 11360 events)\n",
      "Place: 9\n",
      "Distance: 24.98m (which is 11677 events)\n",
      "Duration: 1.72s (which is 11677 events)\n",
      "Place: 10\n",
      "Distance: 25.00m (which is 15978 events)\n",
      "Duration: 1.63s (which is 15978 events)\n",
      "Place: 11\n",
      "Distance: 25.00m (which is 8261 events)\n",
      "Duration: 1.67s (which is 8261 events)\n",
      "Place: 12\n",
      "Distance: 24.99m (which is 9054 events)\n",
      "Duration: 1.72s (which is 9054 events)\n",
      "Place: 13\n",
      "Distance: 24.99m (which is 11526 events)\n",
      "Duration: 1.71s (which is 11526 events)\n",
      "Place: 14\n",
      "Distance: 25.00m (which is 14723 events)\n",
      "Duration: 1.64s (which is 14723 events)\n",
      "Place: 15\n",
      "Distance: 25.00m (which is 7626 events)\n",
      "Duration: 1.70s (which is 7626 events)\n",
      "Place: 16\n",
      "Distance: 24.99m (which is 6426 events)\n",
      "Duration: 1.96s (which is 6426 events)\n",
      "Place: 17\n",
      "Distance: 24.56m (which is 600 events)\n",
      "Duration: 2.00s (which is 600 events)\n",
      "Place: 18\n",
      "Distance: 24.99m (which is 4076 events)\n",
      "Duration: 1.66s (which is 4076 events)\n",
      "Place: 19\n",
      "Distance: 25.00m (which is 2434 events)\n",
      "Duration: 1.51s (which is 2434 events)\n",
      "Place: 20\n",
      "Distance: 24.96m (which is 1459 events)\n",
      "Duration: 1.45s (which is 1459 events)\n",
      "Place: 21\n",
      "Distance: 24.99m (which is 1231 events)\n",
      "Duration: 1.43s (which is 1231 events)\n",
      "Place: 22\n",
      "Distance: 25.00m (which is 902 events)\n",
      "Duration: 1.41s (which is 902 events)\n",
      "Place: 23\n",
      "Distance: 25.00m (which is 2161 events)\n",
      "Duration: 1.52s (which is 2161 events)\n",
      "Place: 24\n",
      "Distance: 24.97m (which is 587 events)\n",
      "Duration: 1.51s (which is 587 events)\n",
      "Place: 25\n",
      "Distance: 25.00m (which is 1494 events)\n",
      "Duration: 1.58s (which is 1494 events)\n",
      "Place: 26\n",
      "Distance: 25.00m (which is 8176 events)\n",
      "Duration: 1.71s (which is 8176 events)\n",
      "Place: 27\n",
      "Distance: 25.00m (which is 4727 events)\n",
      "Duration: 1.68s (which is 4727 events)\n",
      "Place: 28\n",
      "Distance: 25.00m (which is 9188 events)\n",
      "Duration: 1.68s (which is 9188 events)\n",
      "Place: 29\n",
      "Distance: 24.99m (which is 9446 events)\n",
      "Duration: 1.67s (which is 9446 events)\n",
      "Place: 30\n",
      "Distance: 25.00m (which is 7958 events)\n",
      "Duration: 1.62s (which is 7958 events)\n",
      "Place: 31\n",
      "Distance: 25.00m (which is 14311 events)\n",
      "Duration: 11.66s (which is 14311 events)\n",
      "Place: 32\n",
      "Distance: 25.00m (which is 17386 events)\n",
      "Duration: 2.42s (which is 17386 events)\n",
      "Place: 33\n",
      "Distance: 25.00m (which is 9492 events)\n",
      "Duration: 2.95s (which is 9492 events)\n",
      "Place: 34\n",
      "Distance: 24.99m (which is 11942 events)\n",
      "Duration: 2.29s (which is 11942 events)\n",
      "Place: 35\n",
      "Distance: 24.98m (which is 6761 events)\n",
      "Duration: 2.90s (which is 6761 events)\n",
      "Place: 36\n",
      "Distance: 25.00m (which is 6799 events)\n",
      "Duration: 2.40s (which is 6799 events)\n",
      "Place: 37\n",
      "Distance: 25.00m (which is 3072 events)\n",
      "Duration: 1.82s (which is 3072 events)\n",
      "Place: 38\n",
      "Distance: 25.00m (which is 10008 events)\n",
      "Duration: 1.75s (which is 10008 events)\n",
      "Place: 39\n",
      "Distance: 25.00m (which is 4530 events)\n",
      "Duration: 1.71s (which is 4530 events)\n",
      "Place: 40\n",
      "Distance: 25.00m (which is 12244 events)\n",
      "Duration: 1.54s (which is 12244 events)\n",
      "Place: 41\n",
      "Distance: 25.00m (which is 7888 events)\n",
      "Duration: 1.65s (which is 7888 events)\n",
      "Place: 42\n",
      "Distance: 25.00m (which is 13298 events)\n",
      "Duration: 1.59s (which is 13298 events)\n",
      "Place: 43\n",
      "Distance: 25.00m (which is 12713 events)\n",
      "Duration: 1.69s (which is 12713 events)\n",
      "Place: 44\n",
      "Distance: 25.00m (which is 15903 events)\n",
      "Duration: 1.76s (which is 15903 events)\n",
      "The number of testing substreams is: 45\n"
     ]
    }
   ],
   "source": [
    "# Load the data\n",
    "training_set = BrisbaneVPRDatasetSpeed(train_traverse, train=True, place_length = place_length, place_gap=place_gap, num_places=num_places, start_dist=start_dist,samples_per_sec=samples_per_sec, max_spikes=max_spikes)\n",
    "testing_set  = BrisbaneVPRDatasetSpeed(test_traverse, train=False, place_length = place_length, training_locations=training_set.place_locations, place_gap=place_gap, num_places=num_places, start_dist=start_dist, samples_per_sec=samples_per_sec, max_spikes=max_spikes)\n",
    "            \n",
    "train_loader = DataLoader(dataset=training_set, batch_size=batch_size, shuffle=True)\n",
    "test_loader  = DataLoader(dataset=testing_set , batch_size=batch_size, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch  0/50] Train loss =     0.77156 | Test  loss =     0.66821                        accuracy = 0.02222\n",
      "Accuracy was none\n",
      "\n",
      "Accuracy was none\n",
      "[Epoch  1/50] Train loss =     0.61527 (min =     0.77156)    accuracy = 0.11111  | Test  loss =     0.66526 (min =     0.66821)    accuracy = 0.04444 (max = 0.02222)\n",
      "Accuracy was none\n",
      "[Epoch  2/50] Train loss =     0.54038 (min =     0.61527)    accuracy = 0.13333 (max = 0.11111) | Test  loss =     0.65248 (min =     0.66526)    accuracy = 0.08889 (max = 0.04444)\n",
      "Accuracy was none\n",
      "[Epoch  3/50] Train loss =     0.47456 (min =     0.54038)    accuracy = 0.35556 (max = 0.13333) | Test  loss =     0.64395 (min =     0.65248)    accuracy = 0.11111 (max = 0.08889)\n",
      "Accuracy was none\n",
      "[Epoch  4/50] Train loss =     0.44710 (min =     0.47456)    accuracy = 0.28889 (max = 0.35556) | Test  loss =     0.62798 (min =     0.64395)    accuracy = 0.15556 (max = 0.11111)\n",
      "Accuracy was none\n",
      "[Epoch  5/50] Train loss =     0.38818 (min =     0.44710)    accuracy = 0.53333 (max = 0.35556) | Test  loss =     0.62132 (min =     0.62798)    accuracy = 0.13333 (max = 0.15556)\n",
      "Accuracy was none\n",
      "[Epoch  6/50] Train loss =     0.37209 (min =     0.38818)    accuracy = 0.57778 (max = 0.53333) | Test  loss =     0.63817 (min =     0.62132)    accuracy = 0.08889 (max = 0.15556)\n",
      "Accuracy was none\n",
      "[Epoch  7/50] Train loss =     0.35483 (min =     0.37209)    accuracy = 0.68889 (max = 0.57778) | Test  loss =     0.62804 (min =     0.62132)    accuracy = 0.20000 (max = 0.15556)\n",
      "Accuracy was none\n",
      "[Epoch  8/50] Train loss =     0.34104 (min =     0.35483)    accuracy = 0.66667 (max = 0.68889) | Test  loss =     0.61269 (min =     0.62132)    accuracy = 0.20000 (max = 0.20000)\n",
      "Accuracy was none\n",
      "[Epoch  9/50] Train loss =     0.32432 (min =     0.34104)    accuracy = 0.71111 (max = 0.68889) | Test  loss =     0.63267 (min =     0.61269)    accuracy = 0.24444 (max = 0.20000)\n",
      "Accuracy was none\n",
      "[Epoch 10/50] Train loss =     0.30418 (min =     0.32432)    accuracy = 0.80000 (max = 0.71111) | Test  loss =     0.59257 (min =     0.61269)    accuracy = 0.20000 (max = 0.24444)\n",
      "Accuracy was none\n",
      "[Epoch 11/50] Train loss =     0.29601 (min =     0.30418)    accuracy = 0.82222 (max = 0.80000) | Test  loss =     0.64077 (min =     0.59257)    accuracy = 0.20000 (max = 0.24444)\n",
      "Accuracy was none\n",
      "[Epoch 12/50] Train loss =     0.27287 (min =     0.29601)    accuracy = 0.77778 (max = 0.82222) | Test  loss =     0.58677 (min =     0.59257)    accuracy = 0.22222 (max = 0.24444)\n",
      "Accuracy was none\n",
      "[Epoch 13/50] Train loss =     0.27316 (min =     0.27287)    accuracy = 0.80000 (max = 0.82222) | Test  loss =     0.64430 (min =     0.58677)    accuracy = 0.17778 (max = 0.24444)\n",
      "Accuracy was none\n",
      "[Epoch 14/50] Train loss =     0.25604 (min =     0.27287)    accuracy = 0.82222 (max = 0.82222) | Test  loss =     0.58623 (min =     0.58677)    accuracy = 0.28889 (max = 0.24444)\n",
      "Accuracy was none\n",
      "[Epoch 15/50] Train loss =     0.23521 (min =     0.25604)    accuracy = 0.84444 (max = 0.82222) | Test  loss =     0.62298 (min =     0.58623)    accuracy = 0.24444 (max = 0.28889)\n",
      "Accuracy was none\n",
      "[Epoch 16/50] Train loss =     0.24747 (min =     0.23521)    accuracy = 0.86667 (max = 0.84444) | Test  loss =     0.59208 (min =     0.58623)    accuracy = 0.15556 (max = 0.28889)\n",
      "Accuracy was none\n",
      "[Epoch 17/50] Train loss =     0.21666 (min =     0.23521)    accuracy = 0.88889 (max = 0.86667) | Test  loss =     0.62053 (min =     0.58623)    accuracy = 0.26667 (max = 0.28889)\n",
      "Accuracy was none\n",
      "[Epoch 18/50] Train loss =     0.21881 (min =     0.21666)    accuracy = 0.86667 (max = 0.88889) | Test  loss =     0.61057 (min =     0.58623)    accuracy = 0.31111 (max = 0.28889)\n",
      "Accuracy was none\n",
      "                                                                                                                                                                                       \n",
      "[Epoch 19/50]\n",
      "Train loss =     0.20142 (min =     0.21666)    accuracy = 0.91111 (max = 0.88889) \n",
      "Test  loss =     0.62074 (min =     0.58623)    accuracy = 0.22222 (max = 0.31111)\n",
      "\n",
      "Accuracy was none\n",
      "[Epoch 20/50] Train loss =     0.19285 (min =     0.20142)    accuracy = 0.91111 (max = 0.91111) | Test  loss =     0.57342 (min =     0.58623)    accuracy = 0.28889 (max = 0.31111)\n",
      "Accuracy was none\n",
      "[Epoch 21/50] Train loss =     0.21507 (min =     0.19285)    accuracy = 0.91111 (max = 0.91111) | Test  loss =     0.58987 (min =     0.57342)    accuracy = 0.28889 (max = 0.31111)\n",
      "Accuracy was none\n",
      "[Epoch 22/50] Train loss =     0.19800 (min =     0.19285)    accuracy = 0.91111 (max = 0.91111) | Test  loss =     0.60454 (min =     0.57342)    accuracy = 0.31111 (max = 0.31111)\n",
      "Accuracy was none\n",
      "[Epoch 23/50] Train loss =     0.18796 (min =     0.19285)    accuracy = 0.91111 (max = 0.91111) | Test  loss =     0.58579 (min =     0.57342)    accuracy = 0.17778 (max = 0.31111)\n",
      "Accuracy was none\n",
      "[Epoch 24/50] Train loss =     0.18004 (min =     0.18796)    accuracy = 0.88889 (max = 0.91111) | Test  loss =     0.59173 (min =     0.57342)    accuracy = 0.28889 (max = 0.31111)\n",
      "Accuracy was none\n",
      "[Epoch 25/50] Train loss =     0.16978 (min =     0.18004)    accuracy = 0.91111 (max = 0.91111) | Test  loss =     0.59080 (min =     0.57342)    accuracy = 0.26667 (max = 0.31111)\n",
      "Accuracy was none\n",
      "[Epoch 26/50] Train loss =     0.16837 (min =     0.16978)    accuracy = 0.91111 (max = 0.91111) | Test  loss =     0.60843 (min =     0.57342)    accuracy = 0.24444 (max = 0.31111)\n",
      "Accuracy was none\n",
      "[Epoch 27/50] Train loss =     0.15581 (min =     0.16837)    accuracy = 0.93333 (max = 0.91111) | Test  loss =     0.61727 (min =     0.57342)    accuracy = 0.24444 (max = 0.31111)\n",
      "Accuracy was none\n",
      "[Epoch 28/50] Train loss =     0.16186 (min =     0.15581)    accuracy = 0.91111 (max = 0.93333) | Test  loss =     0.61456 (min =     0.57342)    accuracy = 0.24444 (max = 0.31111)\n",
      "Accuracy was none\n",
      "[Epoch 29/50] Train loss =     0.15408 (min =     0.15581)    accuracy = 0.93333 (max = 0.93333) | Test  loss =     0.59991 (min =     0.57342)    accuracy = 0.26667 (max = 0.31111)\n",
      "Accuracy was none\n",
      "[Epoch 30/50] Train loss =     0.15288 (min =     0.15408)    accuracy = 0.91111 (max = 0.93333) | Test  loss =     0.60163 (min =     0.57342)    accuracy = 0.22222 (max = 0.31111)\n",
      "Accuracy was none\n",
      "[Epoch 31/50] Train loss =     0.14172 (min =     0.15288)    accuracy = 0.91111 (max = 0.93333) | Test  loss =     0.60737 (min =     0.57342)    accuracy = 0.33333 (max = 0.31111)\n",
      "Accuracy was none\n",
      "[Epoch 32/50] Train loss =     0.12060 (min =     0.14172)    accuracy = 0.91111 (max = 0.93333) | Test  loss =     0.58502 (min =     0.57342)    accuracy = 0.28889 (max = 0.33333)\n",
      "Accuracy was none\n",
      "[Epoch 33/50] Train loss =     0.15676 (min =     0.12060)    accuracy = 0.91111 (max = 0.93333) | Test  loss =     0.57713 (min =     0.57342)    accuracy = 0.26667 (max = 0.33333)\n",
      "Accuracy was none\n",
      "[Epoch 34/50] Train loss =     0.14980 (min =     0.12060)    accuracy = 0.93333 (max = 0.93333) | Test  loss =     0.62368 (min =     0.57342)    accuracy = 0.31111 (max = 0.33333)\n",
      "Accuracy was none\n",
      "[Epoch 35/50] Train loss =     0.12795 (min =     0.12060)    accuracy = 0.93333 (max = 0.93333) | Test  loss =     0.61303 (min =     0.57342)    accuracy = 0.22222 (max = 0.33333)\n",
      "Accuracy was none\n",
      "[Epoch 36/50] Train loss =     0.13145 (min =     0.12060)    accuracy = 0.93333 (max = 0.93333) | Test  loss =     0.61371 (min =     0.57342)    accuracy = 0.28889 (max = 0.33333)\n",
      "Accuracy was none\n",
      "[Epoch 37/50] Train loss =     0.11777 (min =     0.12060)    accuracy = 0.93333 (max = 0.93333) | Test  loss =     0.60445 (min =     0.57342)    accuracy = 0.24444 (max = 0.33333)\n",
      "Accuracy was none\n",
      "[Epoch 38/50] Train loss =     0.11242 (min =     0.11777)    accuracy = 0.93333 (max = 0.93333) | Test  loss =     0.60391 (min =     0.57342)    accuracy = 0.26667 (max = 0.33333)\n",
      "Accuracy was none\n",
      "                                                                                                                                                                                       \n",
      "[Epoch 39/50]\n",
      "Train loss =     0.10586 (min =     0.11242)    accuracy = 0.93333 (max = 0.93333) \n",
      "Test  loss =     0.61841 (min =     0.57342)    accuracy = 0.33333 (max = 0.33333)\n",
      "\n",
      "Accuracy was none\n",
      "[Epoch 40/50] Train loss =     0.10810 (min =     0.10586)    accuracy = 0.95556 (max = 0.93333) | Test  loss =     0.61640 (min =     0.57342)    accuracy = 0.28889 (max = 0.33333)\n",
      "Accuracy was none\n",
      "[Epoch 41/50] Train loss =     0.09726 (min =     0.10586)    accuracy = 0.95556 (max = 0.95556) | Test  loss =     0.61378 (min =     0.57342)    accuracy = 0.26667 (max = 0.33333)\n",
      "Accuracy was none\n",
      "[Epoch 42/50] Train loss =     0.10657 (min =     0.09726)    accuracy = 0.93333 (max = 0.95556) | Test  loss =     0.61583 (min =     0.57342)    accuracy = 0.31111 (max = 0.33333)\n",
      "Accuracy was none\n",
      "[Epoch 43/50] Train loss =     0.10184 (min =     0.09726)    accuracy = 0.95556 (max = 0.95556) | Test  loss =     0.60574 (min =     0.57342)    accuracy = 0.26667 (max = 0.33333)\n",
      "Accuracy was none\n",
      "[Epoch 44/50] Train loss =     0.09730 (min =     0.09726)    accuracy = 0.93333 (max = 0.95556) | Test  loss =     0.62074 (min =     0.57342)    accuracy = 0.26667 (max = 0.33333)\n",
      "Accuracy was none\n",
      "[Epoch 45/50] Train loss =     0.09140 (min =     0.09726)    accuracy = 0.93333 (max = 0.95556) | Test  loss =     0.60678 (min =     0.57342)    accuracy = 0.22222 (max = 0.33333)\n",
      "Accuracy was none\n",
      "[Epoch 46/50] Train loss =     0.09370 (min =     0.09140)    accuracy = 0.97778 (max = 0.95556) | Test  loss =     0.62866 (min =     0.57342)    accuracy = 0.28889 (max = 0.33333)\n",
      "Accuracy was none\n",
      "[Epoch 47/50] Train loss =     0.08524 (min =     0.09140)    accuracy = 0.97778 (max = 0.97778) | Test  loss =     0.61087 (min =     0.57342)    accuracy = 0.24444 (max = 0.33333)\n",
      "Accuracy was none\n",
      "[Epoch 48/50] Train loss =     0.07566 (min =     0.08524)    accuracy = 0.97778 (max = 0.97778) | Test  loss =     0.61538 (min =     0.57342)    accuracy = 0.33333 (max = 0.33333)\n",
      "Accuracy was none\n",
      "[Epoch 49/50] Train loss =     0.08267 (min =     0.07566)    accuracy = 0.97778 (max = 0.97778) | Test  loss =     0.59780 (min =     0.57342)    accuracy = 0.26667 (max = 0.33333)\n",
      "Accuracy was none\n"
     ]
    }
   ],
   "source": [
    "# Define an optimiser \n",
    "optimizer = torch.optim.Adam(net.parameters(), lr=0.001)\n",
    "\n",
    "# Training the network\n",
    "error = slayer.loss.SpikeRate(true_rate=0.2, false_rate=0.03, reduction='sum').to(device)\n",
    "\n",
    "# Create a training assistant object\n",
    "stats = slayer.utils.LearningStats()\n",
    "assistant = slayer.utils.Assistant(net, error, optimizer, stats, classifier=slayer.classifier.Rate.predict)\n",
    "\n",
    "\n",
    "if redo_plot:\n",
    "    for i, (input, label) in enumerate(train_loader): # training loop\n",
    "        output = assistant.train(input, label)\n",
    "\n",
    "else: \n",
    "    for epoch in range(epochs):\n",
    "\n",
    "        for i, (input, label) in enumerate(train_loader): # training loop\n",
    "            output = assistant.train(input, label)\n",
    "        print(f'\\r[Epoch {epoch:2d}/{epochs}] {stats}', end='')\n",
    "\n",
    "        for i, (input, label) in enumerate(test_loader): # training loop\n",
    "            output = assistant.test(input, label)\n",
    "        print(f'\\r[Epoch {epoch:2d}/{epochs}] {stats}', end='')\n",
    "\n",
    "        if epoch%20 == 19: # cleanup display\n",
    "            print('\\r', ' '*len(f'\\r[Epoch {epoch:2d}/{epochs}] {stats}'))\n",
    "            stats_str = str(stats).replace(\"| \", \"\\n\")\n",
    "            print(f'[Epoch {epoch:2d}/{epochs}]\\n{stats_str}')\n",
    "\n",
    "        if stats.testing.best_accuracy:\n",
    "            torch.save(net.state_dict(), trained_folder + '/network.pt')\n",
    "        stats.update()\n",
    "        stats.save(trained_folder + '/')\n",
    "        net.grad_flow(trained_folder + '/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "CUDA out of memory. Tried to allocate 80.00 MiB (GPU 0; 23.70 GiB total capacity; 1.46 GiB already allocated; 46.00 MiB free; 1.53 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[1;32m/home/n10223622/snn-event-vpr/src/software_pipeline_speed.ipynb Cell 6\u001b[0m in \u001b[0;36m<cell line: 9>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      <a href='vscode-notebook-cell://ssh-remote%2Bvenus.qut.edu.au/home/n10223622/snn-event-vpr/src/software_pipeline_speed.ipynb#W5sdnNjb2RlLXJlbW90ZQ%3D%3D?line=7'>8</a>\u001b[0m labels \u001b[39m=\u001b[39m []\n\u001b[1;32m      <a href='vscode-notebook-cell://ssh-remote%2Bvenus.qut.edu.au/home/n10223622/snn-event-vpr/src/software_pipeline_speed.ipynb#W5sdnNjb2RlLXJlbW90ZQ%3D%3D?line=8'>9</a>\u001b[0m \u001b[39mfor\u001b[39;00m i, (\u001b[39minput\u001b[39m, label) \u001b[39min\u001b[39;00m \u001b[39menumerate\u001b[39m(test_loader2):\n\u001b[0;32m---> <a href='vscode-notebook-cell://ssh-remote%2Bvenus.qut.edu.au/home/n10223622/snn-event-vpr/src/software_pipeline_speed.ipynb#W5sdnNjb2RlLXJlbW90ZQ%3D%3D?line=9'>10</a>\u001b[0m     output \u001b[39m=\u001b[39m net(\u001b[39minput\u001b[39;49m\u001b[39m.\u001b[39;49mto(device)) \u001b[39m# Get network output\u001b[39;00m\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2Bvenus.qut.edu.au/home/n10223622/snn-event-vpr/src/software_pipeline_speed.ipynb#W5sdnNjb2RlLXJlbW90ZQ%3D%3D?line=10'>11</a>\u001b[0m     \u001b[39m#guesses = assistant.classifier(output).cpu().data.numpy() # get the predictions \u001b[39;00m\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2Bvenus.qut.edu.au/home/n10223622/snn-event-vpr/src/software_pipeline_speed.ipynb#W5sdnNjb2RlLXJlbW90ZQ%3D%3D?line=11'>12</a>\u001b[0m     rate\u001b[39m.\u001b[39mextend(Rate\u001b[39m.\u001b[39mrate(output)\u001b[39m.\u001b[39mcpu()\u001b[39m.\u001b[39mdata\u001b[39m.\u001b[39mnumpy()) \u001b[39m# Get the firing rates for each place \u001b[39;00m\n",
      "File \u001b[0;32m~/mambaforge/envs/lavaenv/lib/python3.10/site-packages/torch/nn/modules/module.py:1110\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1106\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1107\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1108\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1109\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1110\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39;49m\u001b[39minput\u001b[39;49m, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m   1111\u001b[0m \u001b[39m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1112\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[39m=\u001b[39m [], []\n",
      "File \u001b[0;32m~/snn-event-vpr/src/VPRNetwork.py:30\u001b[0m, in \u001b[0;36mVPRNetwork.forward\u001b[0;34m(self, spike)\u001b[0m\n\u001b[1;32m     28\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mforward\u001b[39m(\u001b[39mself\u001b[39m, spike):\n\u001b[1;32m     29\u001b[0m     \u001b[39mfor\u001b[39;00m block \u001b[39min\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mblocks:\n\u001b[0;32m---> 30\u001b[0m         spike \u001b[39m=\u001b[39m block(spike)\n\u001b[1;32m     31\u001b[0m     \u001b[39mreturn\u001b[39;00m spike\n",
      "File \u001b[0;32m~/mambaforge/envs/lavaenv/lib/python3.10/site-packages/torch/nn/modules/module.py:1110\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1106\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1107\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1108\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1109\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1110\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39;49m\u001b[39minput\u001b[39;49m, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m   1111\u001b[0m \u001b[39m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1112\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[39m=\u001b[39m [], []\n",
      "File \u001b[0;32m~/mambaforge/envs/lavaenv/lib/python3.10/site-packages/lava/lib/dl/slayer/block/base.py:508\u001b[0m, in \u001b[0;36mAbstractDense.forward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m    505\u001b[0m         \u001b[39mself\u001b[39m\u001b[39m.\u001b[39msynapse\u001b[39m.\u001b[39mweight\u001b[39m.\u001b[39mdata \u001b[39m*\u001b[39m\u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mmask\n\u001b[1;32m    507\u001b[0m z \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39msynapse(x)\n\u001b[0;32m--> 508\u001b[0m x \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mneuron(z)\n\u001b[1;32m    509\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdelay_shift \u001b[39mis\u001b[39;00m \u001b[39mTrue\u001b[39;00m:\n\u001b[1;32m    510\u001b[0m     x \u001b[39m=\u001b[39m delay(x, \u001b[39m1\u001b[39m)\n",
      "File \u001b[0;32m~/mambaforge/envs/lavaenv/lib/python3.10/site-packages/torch/nn/modules/module.py:1110\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1106\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1107\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1108\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1109\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1110\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39;49m\u001b[39minput\u001b[39;49m, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m   1111\u001b[0m \u001b[39m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1112\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[39m=\u001b[39m [], []\n",
      "File \u001b[0;32m~/mambaforge/envs/lavaenv/lib/python3.10/site-packages/lava/lib/dl/slayer/neuron/cuba.py:434\u001b[0m, in \u001b[0;36mNeuron.forward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    418\u001b[0m \u001b[39m\"\"\"Computes the full response of the neuron instance to an input.\u001b[39;00m\n\u001b[1;32m    419\u001b[0m \u001b[39mThe input shape must match with the neuron shape. For the first time,\u001b[39;00m\n\u001b[1;32m    420\u001b[0m \u001b[39mthe neuron shape is determined from the input automatically.\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    431\u001b[0m \n\u001b[1;32m    432\u001b[0m \u001b[39m\"\"\"\u001b[39;00m\n\u001b[1;32m    433\u001b[0m _, voltage \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdynamics(\u001b[39minput\u001b[39m)\n\u001b[0;32m--> 434\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mspike(voltage)\n",
      "File \u001b[0;32m~/mambaforge/envs/lavaenv/lib/python3.10/site-packages/lava/lib/dl/slayer/neuron/cuba.py:396\u001b[0m, in \u001b[0;36mNeuron.spike\u001b[0;34m(self, voltage)\u001b[0m\n\u001b[1;32m    381\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mspike\u001b[39m(\u001b[39mself\u001b[39m, voltage):\n\u001b[1;32m    382\u001b[0m     \u001b[39m\"\"\"Extracts spike points from the voltage timeseries. It assumes the\u001b[39;00m\n\u001b[1;32m    383\u001b[0m \u001b[39m    reset dynamics is already applied.\u001b[39;00m\n\u001b[1;32m    384\u001b[0m \n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    394\u001b[0m \n\u001b[1;32m    395\u001b[0m \u001b[39m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 396\u001b[0m     spike \u001b[39m=\u001b[39m Spike\u001b[39m.\u001b[39;49mapply(\n\u001b[1;32m    397\u001b[0m         voltage, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mthreshold,\n\u001b[1;32m    398\u001b[0m         \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mtau_rho \u001b[39m*\u001b[39;49m TAU_RHO_MULT,\n\u001b[1;32m    399\u001b[0m         \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mscale_rho \u001b[39m*\u001b[39;49m SCALE_RHO_MULT,\n\u001b[1;32m    400\u001b[0m         \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mgraded_spike,\n\u001b[1;32m    401\u001b[0m         \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mvoltage_state,\n\u001b[1;32m    402\u001b[0m         \u001b[39m# self.s_scale,\u001b[39;49;00m\n\u001b[1;32m    403\u001b[0m         \u001b[39m1\u001b[39;49m,\n\u001b[1;32m    404\u001b[0m     )\n\u001b[1;32m    406\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mpersistent_state \u001b[39mis\u001b[39;00m \u001b[39mTrue\u001b[39;00m:\n\u001b[1;32m    407\u001b[0m         \u001b[39mwith\u001b[39;00m torch\u001b[39m.\u001b[39mno_grad():\n",
      "File \u001b[0;32m~/mambaforge/envs/lavaenv/lib/python3.10/site-packages/lava/lib/dl/slayer/spike/spike.py:88\u001b[0m, in \u001b[0;36mSpike.forward\u001b[0;34m(ctx, voltage, threshold, tau_rho, scale_rho, graded_spike, voltage_last, scale)\u001b[0m\n\u001b[1;32m     86\u001b[0m     spikes \u001b[39m=\u001b[39m ((voltage \u001b[39m>\u001b[39m\u001b[39m=\u001b[39m threshold) \u001b[39m*\u001b[39m voltage \u001b[39m/\u001b[39m scale)\u001b[39m.\u001b[39mto(dtype)\n\u001b[1;32m     87\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m---> 88\u001b[0m     spikes \u001b[39m=\u001b[39m (voltage \u001b[39m>\u001b[39;49m\u001b[39m=\u001b[39;49m threshold)\u001b[39m.\u001b[39;49mto(dtype)\n\u001b[1;32m     90\u001b[0m graded_spike \u001b[39m=\u001b[39m \u001b[39m1\u001b[39m \u001b[39mif\u001b[39;00m graded_spike \u001b[39mis\u001b[39;00m \u001b[39mTrue\u001b[39;00m \u001b[39melse\u001b[39;00m \u001b[39m0\u001b[39m\n\u001b[1;32m     91\u001b[0m \u001b[39mif\u001b[39;00m torch\u001b[39m.\u001b[39mis_tensor(threshold) \u001b[39mis\u001b[39;00m \u001b[39mFalse\u001b[39;00m:\n",
      "\u001b[0;31mRuntimeError\u001b[0m: CUDA out of memory. Tried to allocate 80.00 MiB (GPU 0; 23.70 GiB total capacity; 1.46 GiB already allocated; 46.00 MiB free; 1.53 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF"
     ]
    }
   ],
   "source": [
    "# import the best network during training \n",
    "net.load_state_dict(torch.load(trained_folder + '/network.pt'))\n",
    "net.export_hdf5(trained_folder + '/network.net')\n",
    "\n",
    "# Get the output for the input to each place\n",
    "test_loader2  = DataLoader(dataset=testing_set , batch_size=batch_size, shuffle=False)\n",
    "rate = []\n",
    "labels = []\n",
    "for i, (input, label) in enumerate(test_loader2):\n",
    "    output = net(input.to(device)) # Get network output\n",
    "    #guesses = assistant.classifier(output).cpu().data.numpy() # get the predictions \n",
    "    rate.extend(Rate.rate(output).cpu().data.numpy()) # Get the firing rates for each place \n",
    "    labels.extend(label.cpu().data.numpy()) # Get place labels\n",
    "\n",
    "\n",
    "# # Get rates in percentages of total\n",
    "# for i in range(num_places):\n",
    "#     sum = np.sum(rate[i])\n",
    "#     if sum != 0:\n",
    "#         rate[i] = np.divide(rate[i],sum)\n",
    "\n",
    "# Make confusion matrix annotations\n",
    "accuracy = 0\n",
    "matches = []\n",
    "annotations = [['' for i in range(num_places)] for j in range(num_places)]\n",
    "for qryIndex in range(num_places):\n",
    "    max_idx = np.argmax(rate[qryIndex])\n",
    "    matches.append(max_idx)\n",
    "    annotations[max_idx][qryIndex] = 'x'\n",
    "    if max_idx ==qryIndex:\n",
    "        accuracy += 1\n",
    "\n",
    "\n",
    "#--------------- Apply a sequencer ------------------#\n",
    "I = np.identity(sequence_length)\n",
    "conv = signal.convolve2d(rate, I, mode='same')\n",
    "print(np.shape(conv))\n",
    "\n",
    "# Make confusion matrix annotations\n",
    "accuracy_s = 0\n",
    "matches_with_seq = []\n",
    "annotations_s = [['' for i in range(num_places)] for j in range(num_places)]\n",
    "for qryIndex in range(num_places):\n",
    "    max_idx = np.argmax(conv[qryIndex])\n",
    "    matches_with_seq.append(max_idx)\n",
    "    annotations_s[max_idx][qryIndex] = 'x'\n",
    "    if max_idx == qryIndex:\n",
    "        accuracy_s += 1\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "help\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 1296x288 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 1296x288 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "\n",
    "#--------------- Save Results ------------------#\n",
    "\n",
    "# Make new folder for results\n",
    "from tracemalloc import start\n",
    "from plotting import plot_gps\n",
    "\n",
    "\n",
    "time_stamp = datetime.now().strftime('%Y-%m-%d_%H-%M-%S')\n",
    "results_path = \"./../results/\" + time_stamp\n",
    "os.mkdir(results_path)\n",
    "\n",
    "\n",
    "# Save query and match images \n",
    "images_path = results_path + \"/matched_images\"\n",
    "images_path_seq = results_path + \"/matched_images_seq\"\n",
    "os.mkdir(images_path)\n",
    "os.mkdir(images_path_seq)\n",
    "\n",
    "print('help')\n",
    "plot_match_images(images_path + \"/\", matches, training_set.place_images, testing_set.place_images)\n",
    "plot_match_images(images_path_seq + \"/\", matches_with_seq, training_set.place_images, testing_set.place_images)\n",
    "\n",
    "# Save the confusion matrices\n",
    "confusion_path = results_path + \"/confusion_matrices\"\n",
    "os.mkdir(confusion_path)\n",
    "rate = transpose(rate)\n",
    "conv = transpose(conv)\n",
    "output_path = confusion_path + \"/confusion_matrix\" \n",
    "output_path_s = confusion_path + \"/confusion_matrix_seq\" \n",
    "plot_confusion_matrix(rate, labels, annotations, output_path, vmin, vmax)\n",
    "plot_confusion_matrix(conv, labels, annotations_s, output_path_s, vmin, vmax)\n",
    "\n",
    "# Save GPS map'\n",
    "gps_path = results_path + \"/gps_locations\"\n",
    "plot_gps(gps_path, training_set.place_locations, testing_set.place_locations)\n",
    "\n",
    "# Save test settings and accuracy\n",
    "accuracy = accuracy/num_places\n",
    "accuracy_s = accuracy_s/num_places\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The accuracy of the network is: 0.3333333333333333\n",
      "The accuracy with a sequencer is: 0.5333333333333333\n"
     ]
    }
   ],
   "source": [
    "\n",
    "log_path = results_path + \"/log.txt\"\n",
    "log_string  = \"\"\"\n",
    "---- DATA SETTINGS ---- \n",
    "Training datasets = {}\n",
    "Testing datasets = {} \n",
    "# Places = {}\n",
    "Start dist = {} [m]\n",
    "Place gap = {} [m]\n",
    "Place length = {} [m]\n",
    "Samples per second = {} \n",
    "Max spikes per sample = {}\n",
    "---- NETWORK SETTINGS ---- \n",
    "Input size = {}x{} \n",
    "Threshold = {}\n",
    "---- TRAINING SETTINGS ---- \n",
    "Epochs = {}\n",
    "Batch size = {}\n",
    "---- SEQUENCER SETTINGS ----\n",
    "Sequence lengtth = {} \n",
    "---- RESULTS ----\n",
    "Accuracy = {}\n",
    "Accuracy (sequencer) = {}\n",
    "\"\"\".format(train_name,test_name,num_places,start_dist,place_gap,place_length,\n",
    "                samples_per_sec,max_spikes,input_size,input_size,threshold,epochs,\n",
    "                batch_size,sequence_length,accuracy,accuracy_s)\n",
    "f = open(log_path,'w')\n",
    "f.write(log_string)\n",
    "f.close()\n",
    "\n",
    "print(\"The accuracy of the network is: \" + str(accuracy))\n",
    "print(\"The accuracy with a sequencer is: \" + str(accuracy_s))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.4 ('lavaenv')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "63e713066215dbc07efbeb034515a5b964b6ad27977c03151c829f7f04a8001d"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
