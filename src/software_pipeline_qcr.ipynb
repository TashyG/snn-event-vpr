{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "%%% Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from __future__ import annotations\n",
    "from time import time\n",
    "from QCRVPRDataset import QCRVPRDataset, QCRVPRSyncDataset\n",
    "from VPRNetwork import VPRNetwork\n",
    "from plotting import plot_confusion_matrix, plot_match_images, plot_gps\n",
    "from constants import brisbane_event_traverses, qcr_traverses, brisbane_event_traverses_aliases\n",
    "from utils import get_short_traverse_name\n",
    "\n",
    "import os, sys\n",
    "import torch\n",
    "from torch.utils.data import DataLoader\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib import animation\n",
    "from scipy import signal\n",
    "from datetime import datetime\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "import lava.lib.dl.slayer as slayer\n",
    "from lava.lib.dl.slayer.classifier import Rate\n",
    "\n",
    "from constants import synced_times"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "22\n",
      "True\n"
     ]
    }
   ],
   "source": [
    "# Training settings\n",
    "from cgi import test\n",
    "\n",
    "\n",
    "epochs = 50\n",
    "batch_size = 10\n",
    "\n",
    "# Network settings\n",
    "input_size = 34\n",
    "threshold = 1\n",
    "\n",
    "# Data settings\n",
    "train_traverse = qcr_traverses[15]\n",
    "test_traverse = qcr_traverses[14]\n",
    "train_name = get_short_traverse_name(train_traverse)\n",
    "test_name = get_short_traverse_name(test_traverse)\n",
    "# num_places = 82\n",
    "# start_time = 0\n",
    "# place_gap = 2 #164/num_places # The streams run for approximately 164 seconds \n",
    "samples_per_sec = 1000\n",
    "place_duration = 5 #5\n",
    "max_spikes = 2762 #2799\n",
    "\n",
    "use_pre_synced_times = True\n",
    "incorporate_speed = True # Cant incorporate speed unless using presynced times\n",
    "\n",
    "match_tolerance = 0\n",
    "\n",
    "if use_pre_synced_times:\n",
    "    num_places = len(synced_times[train_traverse])\n",
    "    print(num_places)\n",
    "\n",
    "# Sequencer settings\n",
    "sequence_length = 3\n",
    "\n",
    "# Plot settings\n",
    "redo_plot = False\n",
    "vmin = 0\n",
    "vmax = 0.19\n",
    "\n",
    "def transpose( matrix):\n",
    "    if len(matrix) == 0:\n",
    "        return []\n",
    "    return [[matrix[i][j] for i in range(len(matrix))] for j in range(len(matrix[0]))]\n",
    "\n",
    "\n",
    "# Use GPU\n",
    "print(torch.cuda.is_available())\n",
    "device = torch.device('cuda')\n",
    "\n",
    "#---------------- Create the Network -----------------#\n",
    "\n",
    "# Create the network\n",
    "net = VPRNetwork(input_size, num_places, threshold=threshold).to(device)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading training event streams ...\n"
     ]
    },
    {
     "data": {
      "application/json": {
       "ascii": false,
       "bar_format": null,
       "colour": null,
       "elapsed": 0.014615297317504883,
       "initial": 0,
       "n": 0,
       "ncols": null,
       "nrows": null,
       "postfix": null,
       "prefix": "",
       "rate": null,
       "total": 1,
       "unit": "it",
       "unit_divisor": 1000,
       "unit_scale": false
      },
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "dfcb80630c10413d9d5e9921d2a0a045",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Duration: 267.00s (which is 51609087 events)\n",
      "[1648433034.33, 1648433048.06, 1648433063.64, 1648433077.47, 1648433091.34, 1648433105.65, 1648433120.19, 1648433133.24, 1648433144.55, 1648433151.05, 1648433163.63, 1648433177.62, 1648433193.01, 1648433206.73, 1648433220.38, 1648433232.07, 1648433242.7, 1648433253.0, 1648433263.31, 1648433272.6, 1648433282.51, 1648433291.85]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/n10223622/snn-event-vpr/src/QCRVPRDataset.py:193: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  event_stream['x'].loc[small_filt0x] = i\n",
      "/home/n10223622/snn-event-vpr/src/QCRVPRDataset.py:197: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  event_stream['y'].loc[small_filt0y] = i\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.936287\n",
      "1.229313\n",
      "1.448187\n",
      "1.965396\n",
      "1.139994\n",
      "2.895014\n",
      "0.543805\n",
      "0.989688\n",
      "1.351823\n",
      "0.905764\n",
      "4.065003\n",
      "1.459383\n",
      "1.543933\n",
      "1.935831\n",
      "0.866582\n",
      "1.54055\n",
      "1.028766\n",
      "0.827075\n",
      "3.939881\n",
      "1.651236\n",
      "0.490808\n",
      "0.148144\n",
      "average spikes = 2762.0\n",
      "The number of training substreams is: 22\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/n10223622/snn-event-vpr/src/QCRVPRDataset.py:77: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  chopped_stream['t'] -= chop_start\n"
     ]
    },
    {
     "data": {
      "application/json": {
       "ascii": false,
       "bar_format": null,
       "colour": null,
       "elapsed": 0.01077413558959961,
       "initial": 0,
       "n": 0,
       "ncols": null,
       "nrows": null,
       "postfix": null,
       "prefix": "",
       "rate": null,
       "total": 1,
       "unit": "it",
       "unit_divisor": 1000,
       "unit_scale": false
      },
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "16685ad24be9442fbec1f1b16ae6ab2f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Duration: 64.50s (which is 39592357 events)\n",
      "[1648432912.91, 1648432915.03, 1648432918.1, 1648432921.15, 1648432924.06, 1648432927.01, 1648432930.13, 1648432933.15, 1648432936.1, 1648432939.18, 1648432942.01, 1648432945.04, 1648432948.16, 1648432951.02, 1648432954.11, 1648432957.06, 1648432960.14, 1648432963.08, 1648432966.15, 1648432969.01, 1648432972.12, 1648432975.02]\n",
      "Place duration 1.2078650594411442\n",
      "Speed ratio 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/n10223622/snn-event-vpr/src/QCRVPRDataset.py:193: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  event_stream['x'].loc[small_filt0x] = i\n",
      "/home/n10223622/snn-event-vpr/src/QCRVPRDataset.py:197: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  event_stream['y'].loc[small_filt0y] = i\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.348232\n",
      "0.328269\n",
      "0.48903\n",
      "0.364701\n",
      "0.258425\n",
      "0.505897\n",
      "0.312104\n",
      "0.314162\n",
      "0.678405\n",
      "0.247867\n",
      "0.849393\n",
      "0.303723\n",
      "0.2881\n",
      "0.536441\n",
      "0.304136\n",
      "0.481545\n",
      "0.318251\n",
      "0.191217\n",
      "0.687149\n",
      "0.429144\n",
      "0.553609\n",
      "0.375824\n",
      "average spikes = 2762.0\n",
      "The number of testing substreams is: 22\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/n10223622/snn-event-vpr/src/QCRVPRDataset.py:77: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  chopped_stream['t'] -= chop_start\n"
     ]
    }
   ],
   "source": [
    "# Load the data\n",
    "if use_pre_synced_times:\n",
    "    training_set = QCRVPRSyncDataset(train_traverse, train=True, place_duration = place_duration, samples_per_sec=samples_per_sec, max_spikes=max_spikes, subselect_num=input_size)\n",
    "    if incorporate_speed:\n",
    "        testing_set  = QCRVPRSyncDataset(test_traverse, train=False, place_duration = place_duration, samples_per_sec=samples_per_sec, max_spikes=max_spikes, subselect_num=input_size, training_duration=training_set.training_duration) # training_duration=training_set.training_duration\n",
    "    else:\n",
    "        testing_set  = QCRVPRSyncDataset(test_traverse, train=False, place_duration = place_duration, samples_per_sec=samples_per_sec, max_spikes=max_spikes, subselect_num=input_size)\n",
    "\n",
    "else: \n",
    "    training_set = QCRVPRDataset(train_traverse, train=True, place_duration = place_duration, place_gap=place_gap, num_places=num_places, start_time=start_time,samples_per_sec=samples_per_sec, max_spikes=max_spikes, subselect_num=input_size)\n",
    "    testing_set  = QCRVPRDataset(test_traverse, train=False, place_duration = place_duration, place_gap=place_gap, num_places=num_places, start_time=start_time, samples_per_sec=samples_per_sec, max_spikes=max_spikes, subselect_num=input_size)\n",
    "\n",
    "    # if incorporate_speed:\n",
    "    #     testing_set  = QCRVPRDataset(test_traverse, train=False, place_duration = place_duration, place_gap=place_gap, num_places=num_places, start_time=start_time, samples_per_sec=samples_per_sec, max_spikes=max_spikes, subselect_num=input_size, relative_place_times=training_set.relative_place_times, training_duration=training_set.training_duration) # training_duration=training_set.training_duration\n",
    "    # else:\n",
    "    #     testing_set  = QCRVPRDataset(test_traverse, train=False, place_duration = place_duration, place_gap=place_gap, num_places=num_places, start_time=start_time, samples_per_sec=samples_per_sec, max_spikes=max_spikes, subselect_num=input_size, relative_place_times=training_set.relative_place_times)\n",
    "\n",
    "train_loader = DataLoader(dataset=training_set, batch_size=batch_size, shuffle=True)\n",
    "test_loader  = DataLoader(dataset=testing_set , batch_size=batch_size, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch  0/50] Train loss =     0.52116                        accuracy = 0.04545 | Test  loss =     7.59850                        accuracy = 0.04545\n",
      "Accuracy was none\n",
      "[Epoch  1/50] Train loss =     0.36457 (min =     0.52116)    accuracy = 0.13636 (max = 0.04545) | Test  loss =     7.50261 (min =     7.59850)    accuracy = 0.18182 (max = 0.04545)\n",
      "Accuracy was none\n",
      "[Epoch  2/50] Train loss =     0.26325 (min =     0.36457)    accuracy = 0.59091 (max = 0.13636) | Test  loss =     2.81389 (min =     7.50261)    accuracy = 0.40909 (max = 0.18182)\n",
      "Accuracy was none\n",
      "[Epoch  3/50] Train loss =     0.25944 (min =     0.26325)    accuracy = 0.72727 (max = 0.59091) | Test  loss =     3.09574 (min =     2.81389)    accuracy = 0.40909 (max = 0.40909)\n",
      "Accuracy was none\n",
      "[Epoch  4/50] Train loss =     0.22586 (min =     0.25944)    accuracy = 0.86364 (max = 0.72727) | Test  loss =     5.47842 (min =     2.81389)    accuracy = 0.40909 (max = 0.40909)\n",
      "Accuracy was none\n",
      "[Epoch  5/50] Train loss =     0.19866 (min =     0.22586)    accuracy = 0.90909 (max = 0.86364) | Test  loss =     6.40071 (min =     2.81389)    accuracy = 0.27273 (max = 0.40909)\n",
      "Accuracy was none\n",
      "[Epoch  6/50] Train loss =     0.18037 (min =     0.19866)    accuracy = 0.95455 (max = 0.90909) | Test  loss =     5.30138 (min =     2.81389)    accuracy = 0.36364 (max = 0.40909)\n",
      "Accuracy was none\n",
      "[Epoch  7/50] Train loss =     0.15620 (min =     0.18037)    accuracy = 1.00000 (max = 0.95455) | Test  loss =     4.45875 (min =     2.81389)    accuracy = 0.40909 (max = 0.40909)\n",
      "Accuracy was none\n",
      "[Epoch  8/50] Train loss =     0.13870 (min =     0.15620)    accuracy = 1.00000 (max = 1.00000) | Test  loss =     4.88772 (min =     2.81389)    accuracy = 0.45455 (max = 0.40909)\n",
      "Accuracy was none\n",
      "[Epoch  9/50] Train loss =     0.12780 (min =     0.13870)    accuracy = 1.00000 (max = 1.00000) | Test  loss =     4.80151 (min =     2.81389)    accuracy = 0.59091 (max = 0.45455)\n",
      "Accuracy was none\n",
      "[Epoch 10/50] Train loss =     0.10160 (min =     0.12780)    accuracy = 1.00000 (max = 1.00000) | Test  loss =     5.20225 (min =     2.81389)    accuracy = 0.59091 (max = 0.59091)\n",
      "Accuracy was none\n",
      "[Epoch 11/50] Train loss =     0.10340 (min =     0.10160)    accuracy = 1.00000 (max = 1.00000) | Test  loss =     5.04158 (min =     2.81389)    accuracy = 0.59091 (max = 0.59091)\n",
      "Accuracy was none\n",
      "[Epoch 12/50] Train loss =     0.09062 (min =     0.10160)    accuracy = 1.00000 (max = 1.00000) | Test  loss =     4.41739 (min =     2.81389)    accuracy = 0.54545 (max = 0.59091)\n",
      "Accuracy was none\n",
      "[Epoch 13/50] Train loss =     0.08658 (min =     0.09062)    accuracy = 1.00000 (max = 1.00000) | Test  loss =     5.14646 (min =     2.81389)    accuracy = 0.59091 (max = 0.59091)\n",
      "Accuracy was none\n",
      "[Epoch 14/50] Train loss =     0.08230 (min =     0.08658)    accuracy = 1.00000 (max = 1.00000) | Test  loss =     4.75775 (min =     2.81389)    accuracy = 0.54545 (max = 0.59091)\n",
      "Accuracy was none\n",
      "[Epoch 15/50] Train loss =     0.07471 (min =     0.08230)    accuracy = 1.00000 (max = 1.00000) | Test  loss =     4.54590 (min =     2.81389)    accuracy = 0.59091 (max = 0.59091)\n",
      "Accuracy was none\n",
      "[Epoch 16/50] Train loss =     0.06880 (min =     0.07471)    accuracy = 1.00000 (max = 1.00000) | Test  loss =     5.42943 (min =     2.81389)    accuracy = 0.59091 (max = 0.59091)\n",
      "Accuracy was none\n",
      "[Epoch 17/50] Train loss =     0.06857 (min =     0.06880)    accuracy = 1.00000 (max = 1.00000) | Test  loss =     4.77634 (min =     2.81389)    accuracy = 0.63636 (max = 0.59091)\n",
      "Accuracy was none\n",
      "[Epoch 18/50] Train loss =     0.06302 (min =     0.06857)    accuracy = 1.00000 (max = 1.00000) | Test  loss =     4.73969 (min =     2.81389)    accuracy = 0.59091 (max = 0.63636)\n",
      "Accuracy was none\n",
      "                                                                                                                                                                                       \n",
      "[Epoch 19/50]\n",
      "Train loss =     0.06046 (min =     0.06302)    accuracy = 1.00000 (max = 1.00000) \n",
      "Test  loss =     4.86037 (min =     2.81389)    accuracy = 0.68182 (max = 0.63636)\n",
      "\n",
      "Accuracy was none\n",
      "[Epoch 20/50] Train loss =     0.06423 (min =     0.06046)    accuracy = 1.00000 (max = 1.00000) | Test  loss =     4.38747 (min =     2.81389)    accuracy = 0.72727 (max = 0.68182)\n",
      "Accuracy was none\n",
      "[Epoch 21/50] Train loss =     0.06497 (min =     0.06046)    accuracy = 1.00000 (max = 1.00000) | Test  loss =     4.83907 (min =     2.81389)    accuracy = 0.68182 (max = 0.72727)\n",
      "Accuracy was none\n",
      "[Epoch 22/50] Train loss =     0.05735 (min =     0.06046)    accuracy = 1.00000 (max = 1.00000) | Test  loss =     5.18881 (min =     2.81389)    accuracy = 0.72727 (max = 0.72727)\n",
      "Accuracy was none\n",
      "[Epoch 23/50] Train loss =     0.06262 (min =     0.05735)    accuracy = 1.00000 (max = 1.00000) | Test  loss =     4.25852 (min =     2.81389)    accuracy = 0.68182 (max = 0.72727)\n",
      "Accuracy was none\n",
      "[Epoch 24/50] Train loss =     0.05878 (min =     0.05735)    accuracy = 1.00000 (max = 1.00000) | Test  loss =     4.87360 (min =     2.81389)    accuracy = 0.68182 (max = 0.72727)\n",
      "Accuracy was none\n",
      "[Epoch 25/50] Train loss =     0.05942 (min =     0.05735)    accuracy = 1.00000 (max = 1.00000) | Test  loss =     4.02858 (min =     2.81389)    accuracy = 0.63636 (max = 0.72727)\n",
      "Accuracy was none\n",
      "[Epoch 26/50] Train loss =     0.06040 (min =     0.05735)    accuracy = 1.00000 (max = 1.00000) | Test  loss =     4.59809 (min =     2.81389)    accuracy = 0.68182 (max = 0.72727)\n",
      "Accuracy was none\n",
      "[Epoch 27/50] Train loss =     0.05790 (min =     0.05735)    accuracy = 1.00000 (max = 1.00000) | Test  loss =     4.59861 (min =     2.81389)    accuracy = 0.59091 (max = 0.72727)\n",
      "Accuracy was none\n",
      "[Epoch 28/50] Train loss =     0.05804 (min =     0.05735)    accuracy = 1.00000 (max = 1.00000) | Test  loss =     4.89835 (min =     2.81389)    accuracy = 0.63636 (max = 0.72727)\n",
      "Accuracy was none\n",
      "[Epoch 29/50] Train loss =     0.05591 (min =     0.05735)    accuracy = 1.00000 (max = 1.00000) | Test  loss =     4.63547 (min =     2.81389)    accuracy = 0.63636 (max = 0.72727)\n",
      "Accuracy was none\n",
      "[Epoch 30/50] Train loss =     0.06475 (min =     0.05591)    accuracy = 1.00000 (max = 1.00000) | Test  loss =     3.46136 (min =     2.81389)    accuracy = 0.68182 (max = 0.72727)\n",
      "Accuracy was none\n",
      "[Epoch 31/50] Train loss =     0.06097 (min =     0.05591)    accuracy = 1.00000 (max = 1.00000) | Test  loss =     4.05997 (min =     2.81389)    accuracy = 0.63636 (max = 0.72727)\n",
      "Accuracy was none\n",
      "[Epoch 32/50] Train loss =     0.06286 (min =     0.05591)    accuracy = 1.00000 (max = 1.00000) | Test  loss =     4.19701 (min =     2.81389)    accuracy = 0.68182 (max = 0.72727)\n",
      "Accuracy was none\n",
      "[Epoch 33/50] Train loss =     0.06684 (min =     0.05591)    accuracy = 1.00000 (max = 1.00000) | Test  loss =     4.45643 (min =     2.81389)    accuracy = 0.59091 (max = 0.72727)\n",
      "Accuracy was none\n",
      "[Epoch 34/50] Train loss =     0.06478 (min =     0.05591)    accuracy = 1.00000 (max = 1.00000) | Test  loss =     4.18069 (min =     2.81389)    accuracy = 0.72727 (max = 0.72727)\n",
      "Accuracy was none\n",
      "[Epoch 35/50] Train loss =     0.06200 (min =     0.05591)    accuracy = 1.00000 (max = 1.00000) | Test  loss =     4.09054 (min =     2.81389)    accuracy = 0.63636 (max = 0.72727)\n",
      "Accuracy was none\n",
      "[Epoch 36/50] Train loss =     0.06687 (min =     0.05591)    accuracy = 1.00000 (max = 1.00000) | Test  loss =     4.24342 (min =     2.81389)    accuracy = 0.63636 (max = 0.72727)\n",
      "Accuracy was none\n",
      "[Epoch 37/50] Train loss =     0.06700 (min =     0.05591)    accuracy = 1.00000 (max = 1.00000) | Test  loss =     3.83986 (min =     2.81389)    accuracy = 0.68182 (max = 0.72727)\n",
      "Accuracy was none\n",
      "[Epoch 38/50] Train loss =     0.06228 (min =     0.05591)    accuracy = 1.00000 (max = 1.00000) | Test  loss =     5.53963 (min =     2.81389)    accuracy = 0.63636 (max = 0.72727)\n",
      "Accuracy was none\n",
      "                                                                                                                                                                                       \n",
      "[Epoch 39/50]\n",
      "Train loss =     0.07728 (min =     0.05591)    accuracy = 1.00000 (max = 1.00000) \n",
      "Test  loss =     3.56912 (min =     2.81389)    accuracy = 0.77273 (max = 0.72727)\n",
      "\n",
      "Accuracy was none\n",
      "[Epoch 40/50] Train loss =     0.05834 (min =     0.05591)    accuracy = 1.00000 (max = 1.00000) | Test  loss =     3.23158 (min =     2.81389)    accuracy = 0.59091 (max = 0.77273)\n",
      "Accuracy was none\n",
      "[Epoch 41/50] Train loss =     0.06256 (min =     0.05591)    accuracy = 1.00000 (max = 1.00000) | Test  loss =     4.84265 (min =     2.81389)    accuracy = 0.68182 (max = 0.77273)\n",
      "Accuracy was none\n",
      "[Epoch 42/50] Train loss =     0.05599 (min =     0.05591)    accuracy = 1.00000 (max = 1.00000) | Test  loss =     4.46385 (min =     2.81389)    accuracy = 0.68182 (max = 0.77273)\n",
      "Accuracy was none\n",
      "[Epoch 43/50] Train loss =     0.06543 (min =     0.05591)    accuracy = 1.00000 (max = 1.00000) | Test  loss =     3.76207 (min =     2.81389)    accuracy = 0.63636 (max = 0.77273)\n",
      "Accuracy was none\n",
      "[Epoch 44/50] Train loss =     0.05710 (min =     0.05591)    accuracy = 1.00000 (max = 1.00000) | Test  loss =     4.79036 (min =     2.81389)    accuracy = 0.59091 (max = 0.77273)\n",
      "Accuracy was none\n",
      "[Epoch 45/50] Train loss =     0.06221 (min =     0.05591)    accuracy = 1.00000 (max = 1.00000) | Test  loss =     4.28766 (min =     2.81389)    accuracy = 0.68182 (max = 0.77273)\n",
      "Accuracy was none\n",
      "[Epoch 46/50] Train loss =     0.05539 (min =     0.05591)    accuracy = 1.00000 (max = 1.00000) | Test  loss =     3.51937 (min =     2.81389)    accuracy = 0.72727 (max = 0.77273)\n",
      "Accuracy was none\n",
      "[Epoch 47/50] Train loss =     0.06214 (min =     0.05539)    accuracy = 1.00000 (max = 1.00000) | Test  loss =     4.12132 (min =     2.81389)    accuracy = 0.59091 (max = 0.77273)\n",
      "Accuracy was none\n",
      "[Epoch 48/50] Train loss =     0.05588 (min =     0.05539)    accuracy = 1.00000 (max = 1.00000) | Test  loss =     3.70984 (min =     2.81389)    accuracy = 0.63636 (max = 0.77273)\n",
      "Accuracy was none\n",
      "[Epoch 49/50] Train loss =     0.06055 (min =     0.05539)    accuracy = 1.00000 (max = 1.00000) | Test  loss =     4.61037 (min =     2.81389)    accuracy = 0.63636 (max = 0.77273)\n",
      "Accuracy was none\n"
     ]
    }
   ],
   "source": [
    "# Make a folder for all results\n",
    "time_stamp = datetime.now().strftime('%Y-%m-%d_%H-%M-%S')\n",
    "results_path = \"./../results/\" + time_stamp\n",
    "os.mkdir(results_path)\n",
    "\n",
    "\n",
    "# Define an optimiser \n",
    "optimizer = torch.optim.Adam(net.parameters(), lr=0.001)\n",
    "\n",
    "# Training the network\n",
    "error = slayer.loss.SpikeRate(true_rate=0.2, false_rate=0.03, reduction='sum').to(device)\n",
    "\n",
    "# Create a training assistant object\n",
    "stats = slayer.utils.LearningStats()\n",
    "assistant = slayer.utils.Assistant(net, error, optimizer, stats, classifier=slayer.classifier.Rate.predict)\n",
    "\n",
    "\n",
    "if redo_plot:\n",
    "    for i, (input, label) in enumerate(train_loader): # training loop\n",
    "        output = assistant.train(input, label)\n",
    "\n",
    "else: \n",
    "    for epoch in range(epochs):\n",
    "\n",
    "        for i, (input, label) in enumerate(train_loader): # training loop\n",
    "            output = assistant.train(input, label)\n",
    "        print(f'\\r[Epoch {epoch:2d}/{epochs}] {stats}', end='')\n",
    "\n",
    "        for i, (input, label) in enumerate(test_loader): # training loop\n",
    "            output = assistant.test(input, label)\n",
    "        print(f'\\r[Epoch {epoch:2d}/{epochs}] {stats}', end='')\n",
    "\n",
    "        if epoch%20 == 19: # cleanup display\n",
    "            print('\\r', ' '*len(f'\\r[Epoch {epoch:2d}/{epochs}] {stats}'))\n",
    "            stats_str = str(stats).replace(\"| \", \"\\n\")\n",
    "            print(f'[Epoch {epoch:2d}/{epochs}]\\n{stats_str}')\n",
    "\n",
    "        if stats.testing.best_accuracy:\n",
    "            torch.save(net.state_dict(), results_path + '/network.pt')\n",
    "        stats.update()\n",
    "        stats.save(results_path + '/')\n",
    "        net.grad_flow(results_path + '/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(22, 22)\n"
     ]
    }
   ],
   "source": [
    "# import the best network during training \n",
    "net.load_state_dict(torch.load(results_path + '/network.pt'))\n",
    "net.export_hdf5(results_path + '/network.net')\n",
    "\n",
    "# Get the output for the input to each place\n",
    "test_loader2  = DataLoader(dataset=testing_set , batch_size=batch_size, shuffle=False)\n",
    "rate = []\n",
    "labels = []\n",
    "for i, (input, label) in enumerate(test_loader2):\n",
    "    output = net(input.to(device)) # Get network output\n",
    "    #guesses = assistant.classifier(output).cpu().data.numpy() # get the predictions \n",
    "    \n",
    "    rate.extend(Rate.confidence(output).cpu().data.numpy()) # Get the firing rates for each place \n",
    "    labels.extend(label.cpu().data.numpy()) # Get place labels\n",
    "\n",
    "\n",
    "# # Get rates in percentages of total\n",
    "# for i in range(num_places):\n",
    "#     sum = np.sum(rate[i])\n",
    "#     if sum != 0:\n",
    "#         rate[i] = np.divide(rate[i],sum)\n",
    "\n",
    "# Make confusion matrix annotations\n",
    "accuracy = 0\n",
    "matches = []\n",
    "annotations = [['' for i in range(num_places)] for j in range(num_places)]\n",
    "for qryIndex in range(num_places):\n",
    "    max_idx = np.argmax(rate[qryIndex])\n",
    "    matches.append(max_idx)\n",
    "    annotations[max_idx][qryIndex] = 'x'\n",
    "    if abs(max_idx - qryIndex) <= match_tolerance:\n",
    "        accuracy += 1\n",
    "\n",
    "\n",
    "#--------------- Apply a sequencer ------------------#\n",
    "I = np.identity(sequence_length)\n",
    "conv = signal.convolve2d(rate, I, mode='same')\n",
    "print(np.shape(conv))\n",
    "\n",
    "# Make confusion matrix annotations\n",
    "accuracy_s = 0\n",
    "matches_with_seq = []\n",
    "annotations_s = [['' for i in range(num_places)] for j in range(num_places)]\n",
    "for qryIndex in range(num_places):\n",
    "    max_idx = np.argmax(conv[qryIndex])\n",
    "    matches_with_seq.append(max_idx)\n",
    "    annotations_s[max_idx][qryIndex] = 'x'\n",
    "    if abs(max_idx - qryIndex) <= match_tolerance:\n",
    "        accuracy_s += 1\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#--------------- Save Results ------------------#\n",
    "\n",
    "# Make new folder for results\n",
    "from tracemalloc import start\n",
    "from plotting import plot_gps\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# # Save query and match images \n",
    "# images_path = results_path + \"/matched_images\"\n",
    "# images_path_seq = results_path + \"/matched_images_seq\"\n",
    "# os.mkdir(images_path)\n",
    "# os.mkdir(images_path_seq)\n",
    "\n",
    "# # print('help')\n",
    "# plot_match_images(images_path + \"/\", matches, training_set.place_images, testing_set.place_images)\n",
    "# plot_match_images(images_path_seq + \"/\", matches_with_seq, training_set.place_images, testing_set.place_images)\n",
    "\n",
    "#Save the confusion matrices\n",
    "confusion_path = results_path + \"/confusion_matrices\"\n",
    "os.mkdir(confusion_path)\n",
    "rate = transpose(rate)\n",
    "conv = transpose(conv)\n",
    "output_path = confusion_path + \"/confusion_matrix\" \n",
    "output_path_s = confusion_path + \"/confusion_matrix_seq\" \n",
    "plot_confusion_matrix(rate, labels, annotations, output_path, vmin, vmax)\n",
    "plot_confusion_matrix(conv, labels, annotations_s, output_path_s, vmin, vmax)\n",
    "\n",
    "# Save GPS map'\n",
    "# gps_path = results_path + \"/gps_locations\"\n",
    "# plot_gps(gps_path, training_set.place_locations, testing_set.place_locations)\n",
    "\n",
    "# Save test settings and accuracy\n",
    "accuracy = accuracy/num_places\n",
    "accuracy_s = accuracy_s/num_places\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The accuracy of the network is: 0.5909090909090909\n",
      "The accuracy with a sequencer is: 0.9545454545454546\n"
     ]
    }
   ],
   "source": [
    "\n",
    "log_path = results_path + \"/log.txt\"\n",
    "\n",
    "if use_pre_synced_times:\n",
    "    log_string  = \"\"\"\n",
    "    ---- DATA SETTINGS ---- \n",
    "    Training datasets = {}\n",
    "    Testing datasets = {} \n",
    "    # Places = {}\n",
    "    Using presynced times = True\n",
    "    Place duration = {} [s]\n",
    "    Samples per second = {} \n",
    "    Max spikes per sample = {}\n",
    "    Incorporate speed = {}\n",
    "    ---- NETWORK SETTINGS ---- \n",
    "    Input size = {}x{} \n",
    "    Threshold = {}\n",
    "    ---- TRAINING SETTINGS ---- \n",
    "    Epochs = {}\n",
    "    Batch size = {}\n",
    "    ---- SEQUENCER SETTINGS ----\n",
    "    Sequence lengtth = {} \n",
    "    ---- RESULTS ----\n",
    "    Match tolerance = {}\n",
    "    Accuracy = {}\n",
    "    Accuracy (sequencer) = {}\n",
    "    \"\"\".format(train_name,test_name, num_places, place_duration,\n",
    "                    samples_per_sec,max_spikes, incorporate_speed, input_size,input_size,threshold,epochs,\n",
    "                    batch_size,sequence_length,match_tolerance,accuracy,accuracy_s)\n",
    "\n",
    "else: \n",
    "    log_string  = \"\"\"\n",
    "    ---- DATA SETTINGS ---- \n",
    "    Training datasets = {}\n",
    "    Testing datasets = {} \n",
    "    # Places = {}\n",
    "    Start time = {} [s]\n",
    "    Place gap = {} [s]\n",
    "    Place duration = {} [s]\n",
    "    Samples per second = {} \n",
    "    Max spikes per sample = {}\n",
    "    Incorporate speed = {}\n",
    "    ---- NETWORK SETTINGS ---- \n",
    "    Input size = {}x{} \n",
    "    Threshold = {}\n",
    "    ---- TRAINING SETTINGS ---- \n",
    "    Epochs = {}\n",
    "    Batch size = {}\n",
    "    ---- SEQUENCER SETTINGS ----\n",
    "    Sequence lengtth = {} \n",
    "    ---- RESULTS ----\n",
    "    Match tolerance = {}\n",
    "    Accuracy = {}\n",
    "    Accuracy (sequencer) = {}\n",
    "    \"\"\".format(train_name,test_name,num_places,start_time,place_gap,place_duration,\n",
    "                    samples_per_sec,max_spikes, incorporate_speed, input_size,input_size,threshold,epochs,\n",
    "                    batch_size,sequence_length,match_tolerance,accuracy,accuracy_s)\n",
    "f = open(log_path,'w')\n",
    "f.write(log_string)\n",
    "f.close()\n",
    "\n",
    "print(\"The accuracy of the network is: \" + str(accuracy))\n",
    "print(\"The accuracy with a sequencer is: \" + str(accuracy_s))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.4 ('lavaenv')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "63e713066215dbc07efbeb034515a5b964b6ad27977c03151c829f7f04a8001d"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
