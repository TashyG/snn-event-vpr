{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "%%% Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from __future__ import annotations\n",
    "from time import time\n",
    "from QCRVPRDataset import QCRVPRDataset, QCRVPRSyncDataset\n",
    "from VPRNetwork import VPRNetwork\n",
    "from plotting import plot_confusion_matrix, plot_match_images, plot_gps\n",
    "from constants import brisbane_event_traverses, qcr_traverses, brisbane_event_traverses_aliases\n",
    "from utils import get_short_traverse_name\n",
    "\n",
    "import os, sys\n",
    "import torch\n",
    "from torch.utils.data import DataLoader\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib import animation\n",
    "from scipy import signal\n",
    "from datetime import datetime\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "import lava.lib.dl.slayer as slayer\n",
    "from lava.lib.dl.slayer.classifier import Rate\n",
    "\n",
    "from constants import synced_times"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "22\n",
      "True\n"
     ]
    }
   ],
   "source": [
    "# Training settings\n",
    "from cgi import test\n",
    "\n",
    "\n",
    "epochs = 50\n",
    "batch_size = 10\n",
    "\n",
    "# Network settings\n",
    "input_size = 34\n",
    "threshold = 1.0\n",
    "\n",
    "# Data settings\n",
    "train_traverse = qcr_traverses[15]\n",
    "test_traverse = qcr_traverses[14]\n",
    "train_name = get_short_traverse_name(train_traverse)\n",
    "test_name = get_short_traverse_name(test_traverse)\n",
    "num_places = 30\n",
    "start_time = 0\n",
    "place_gap = 5 #164/num_places # The streams run for approximately 164 seconds \n",
    "samples_per_sec = 1000\n",
    "place_duration = 2\n",
    "max_spikes = None\n",
    "\n",
    "use_pre_synced_times = True\n",
    "incorporate_speed = True\n",
    "\n",
    "if use_pre_synced_times:\n",
    "    num_places = len(synced_times[train_traverse])\n",
    "    print(num_places)\n",
    "\n",
    "# Sequencer settings\n",
    "sequence_length = 3\n",
    "\n",
    "# Plot settings\n",
    "redo_plot = False\n",
    "vmin = 0\n",
    "vmax = 0.05\n",
    "\n",
    "def transpose( matrix):\n",
    "    if len(matrix) == 0:\n",
    "        return []\n",
    "    return [[matrix[i][j] for i in range(len(matrix))] for j in range(len(matrix[0]))]\n",
    "\n",
    "\n",
    "# Make a folder for the trained network\n",
    "trained_folder = 'Trained'\n",
    "os.makedirs(trained_folder, exist_ok=True)\n",
    "\n",
    "# Use GPU\n",
    "print(torch.cuda.is_available())\n",
    "device = torch.device('cuda')\n",
    "\n",
    "#---------------- Create the Network -----------------#\n",
    "\n",
    "# Create the network\n",
    "net = VPRNetwork(input_size, num_places, threshold=threshold).to(device)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading training event streams ...\n"
     ]
    },
    {
     "data": {
      "application/json": {
       "ascii": false,
       "bar_format": null,
       "colour": null,
       "elapsed": 0.015076637268066406,
       "initial": 0,
       "n": 0,
       "ncols": null,
       "nrows": null,
       "postfix": null,
       "prefix": "",
       "rate": null,
       "total": 1,
       "unit": "it",
       "unit_divisor": 1000,
       "unit_scale": false
      },
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "eb517f29eead48cda99d36d67f08b6fb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Duration: 267.00s (which is 51609087 events)\n",
      "[1648433034.33, 1648433048.06, 1648433063.64, 1648433077.47, 1648433091.34, 1648433105.65, 1648433120.19, 1648433133.24, 1648433144.55, 1648433151.05, 1648433163.63, 1648433177.62, 1648433193.01, 1648433206.73, 1648433220.38, 1648433232.07, 1648433242.7, 1648433253.0, 1648433263.31, 1648433272.6, 1648433282.51, 1648433291.85]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/n10223622/snn-event-vpr/src/QCRVPRDataset.py:188: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  event_stream['x'].loc[small_filt0x] = i\n",
      "/home/n10223622/snn-event-vpr/src/QCRVPRDataset.py:192: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  event_stream['y'].loc[small_filt0y] = i\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1648433034569249\n",
      "1648433034569249\n",
      "1648433034569249\n",
      "1648433034569249\n",
      "1648433034569249\n",
      "1648433034569249\n",
      "1648433034569249\n",
      "1648433034569249\n",
      "1648433034569249\n",
      "1648433034569249\n",
      "1648433034569249\n",
      "1648433034569249\n",
      "1648433034569249\n",
      "1648433034569249\n",
      "1648433034569249\n",
      "1648433034569249\n",
      "1648433034569249\n",
      "1648433034569249\n",
      "1648433034569249\n",
      "1648433034569249\n",
      "1648433034569249\n",
      "1648433034569249\n",
      "The number of training substreams is: 22\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/n10223622/snn-event-vpr/src/QCRVPRDataset.py:76: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  chopped_stream['t'] -= chop_start\n"
     ]
    },
    {
     "data": {
      "application/json": {
       "ascii": false,
       "bar_format": null,
       "colour": null,
       "elapsed": 0.01067042350769043,
       "initial": 0,
       "n": 0,
       "ncols": null,
       "nrows": null,
       "postfix": null,
       "prefix": "",
       "rate": null,
       "total": 1,
       "unit": "it",
       "unit_divisor": 1000,
       "unit_scale": false
      },
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "19cd701a32784600be824a7b7025a123",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Duration: 64.50s (which is 39592357 events)\n",
      "[1648432912.91, 1648432915.03, 1648432918.1, 1648432921.15, 1648432924.06, 1648432927.01, 1648432930.13, 1648432933.15, 1648432936.1, 1648432939.18, 1648432942.01, 1648432945.04, 1648432948.16, 1648432951.02, 1648432954.11, 1648432957.06, 1648432960.14, 1648432963.08, 1648432966.15, 1648432969.01, 1648432972.12, 1648432975.02]\n",
      "Place duration 0.4831460237764577\n",
      "Speed ratio 0.24157301188822886\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/n10223622/snn-event-vpr/src/QCRVPRDataset.py:188: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  event_stream['x'].loc[small_filt0x] = i\n",
      "/home/n10223622/snn-event-vpr/src/QCRVPRDataset.py:192: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  event_stream['y'].loc[small_filt0y] = i\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1648432912934640\n",
      "1648432912934640\n",
      "1648432912934640\n",
      "1648432912934640\n",
      "1648432912934640\n",
      "1648432912934640\n",
      "1648432912934640\n",
      "1648432912934640\n",
      "1648432912934640\n",
      "1648432912934640\n",
      "1648432912934640\n",
      "1648432912934640\n",
      "1648432912934640\n",
      "1648432912934640\n",
      "1648432912934640\n",
      "1648432912934640\n",
      "1648432912934640\n",
      "1648432912934640\n",
      "1648432912934640\n",
      "1648432912934640\n",
      "1648432912934640\n",
      "1648432912934640\n",
      "The number of testing substreams is: 22\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/n10223622/snn-event-vpr/src/QCRVPRDataset.py:76: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  chopped_stream['t'] -= chop_start\n"
     ]
    }
   ],
   "source": [
    "# Load the data\n",
    "if use_pre_synced_times:\n",
    "    training_set = QCRVPRSyncDataset(train_traverse, train=True, place_duration = place_duration, samples_per_sec=samples_per_sec, max_spikes=max_spikes, subselect_num=input_size)\n",
    "    if incorporate_speed:\n",
    "        testing_set  = QCRVPRSyncDataset(test_traverse, train=False, place_duration = place_duration, samples_per_sec=samples_per_sec, max_spikes=max_spikes, subselect_num=input_size, training_duration=training_set.training_duration) # training_duration=training_set.training_duration\n",
    "    else:\n",
    "        testing_set  = QCRVPRSyncDataset(test_traverse, train=False, place_duration = place_duration, samples_per_sec=samples_per_sec, max_spikes=max_spikes, subselect_num=input_size)\n",
    "\n",
    "else: \n",
    "    training_set = QCRVPRDataset(train_traverse, train=True, place_duration = place_duration, place_gap=place_gap, num_places=num_places, start_time=start_time,samples_per_sec=samples_per_sec, max_spikes=max_spikes, subselect_num=input_size)\n",
    "    if incorporate_speed:\n",
    "        testing_set  = QCRVPRDataset(test_traverse, train=False, place_duration = place_duration, place_gap=place_gap, num_places=num_places, start_time=start_time, samples_per_sec=samples_per_sec, max_spikes=max_spikes, subselect_num=input_size, relative_place_times=training_set.relative_place_times, training_duration=training_set.training_duration) # training_duration=training_set.training_duration\n",
    "    else:\n",
    "        testing_set  = QCRVPRDataset(test_traverse, train=False, place_duration = place_duration, place_gap=place_gap, num_places=num_places, start_time=start_time, samples_per_sec=samples_per_sec, max_spikes=max_spikes, subselect_num=input_size, relative_place_times=training_set.relative_place_times)\n",
    "\n",
    "train_loader = DataLoader(dataset=training_set, batch_size=batch_size, shuffle=True)\n",
    "test_loader  = DataLoader(dataset=testing_set , batch_size=batch_size, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "CUDA out of memory. Tried to allocate 40.00 MiB (GPU 0; 23.70 GiB total capacity; 195.51 MiB already allocated; 8.00 MiB free; 200.00 MiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[1;32m/home/n10223622/snn-event-vpr/src/software_pipeline_qcr.ipynb Cell 5\u001b[0m in \u001b[0;36m<cell line: 12>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2Bvenus.qut.edu.au/home/n10223622/snn-event-vpr/src/software_pipeline_qcr.ipynb#W4sdnNjb2RlLXJlbW90ZQ%3D%3D?line=16'>17</a>\u001b[0m \u001b[39mfor\u001b[39;00m epoch \u001b[39min\u001b[39;00m \u001b[39mrange\u001b[39m(epochs):\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2Bvenus.qut.edu.au/home/n10223622/snn-event-vpr/src/software_pipeline_qcr.ipynb#W4sdnNjb2RlLXJlbW90ZQ%3D%3D?line=18'>19</a>\u001b[0m     \u001b[39mfor\u001b[39;00m i, (\u001b[39minput\u001b[39m, label) \u001b[39min\u001b[39;00m \u001b[39menumerate\u001b[39m(train_loader): \u001b[39m# training loop\u001b[39;00m\n\u001b[0;32m---> <a href='vscode-notebook-cell://ssh-remote%2Bvenus.qut.edu.au/home/n10223622/snn-event-vpr/src/software_pipeline_qcr.ipynb#W4sdnNjb2RlLXJlbW90ZQ%3D%3D?line=19'>20</a>\u001b[0m         output \u001b[39m=\u001b[39m assistant\u001b[39m.\u001b[39;49mtrain(\u001b[39minput\u001b[39;49m, label)\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2Bvenus.qut.edu.au/home/n10223622/snn-event-vpr/src/software_pipeline_qcr.ipynb#W4sdnNjb2RlLXJlbW90ZQ%3D%3D?line=20'>21</a>\u001b[0m     \u001b[39mprint\u001b[39m(\u001b[39mf\u001b[39m\u001b[39m'\u001b[39m\u001b[39m\\r\u001b[39;00m\u001b[39m[Epoch \u001b[39m\u001b[39m{\u001b[39;00mepoch\u001b[39m:\u001b[39;00m\u001b[39m2d\u001b[39m\u001b[39m}\u001b[39;00m\u001b[39m/\u001b[39m\u001b[39m{\u001b[39;00mepochs\u001b[39m}\u001b[39;00m\u001b[39m] \u001b[39m\u001b[39m{\u001b[39;00mstats\u001b[39m}\u001b[39;00m\u001b[39m'\u001b[39m, end\u001b[39m=\u001b[39m\u001b[39m'\u001b[39m\u001b[39m'\u001b[39m)\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2Bvenus.qut.edu.au/home/n10223622/snn-event-vpr/src/software_pipeline_qcr.ipynb#W4sdnNjb2RlLXJlbW90ZQ%3D%3D?line=22'>23</a>\u001b[0m     \u001b[39mfor\u001b[39;00m i, (\u001b[39minput\u001b[39m, label) \u001b[39min\u001b[39;00m \u001b[39menumerate\u001b[39m(test_loader): \u001b[39m# training loop\u001b[39;00m\n",
      "File \u001b[0;32m~/mambaforge/envs/lavaenv/lib/python3.10/site-packages/lava/lib/dl/slayer/utils/assistant.py:121\u001b[0m, in \u001b[0;36mAssistant.train\u001b[0;34m(self, input, target)\u001b[0m\n\u001b[1;32m    119\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m    120\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mlam \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[0;32m--> 121\u001b[0m         output \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mnet(\u001b[39minput\u001b[39;49m)\n\u001b[1;32m    122\u001b[0m     \u001b[39melse\u001b[39;00m:\n\u001b[1;32m    123\u001b[0m         output, net_loss \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mnet(\u001b[39minput\u001b[39m)\n",
      "File \u001b[0;32m~/mambaforge/envs/lavaenv/lib/python3.10/site-packages/torch/nn/modules/module.py:1110\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1106\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1107\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1108\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1109\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1110\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39;49m\u001b[39minput\u001b[39;49m, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m   1111\u001b[0m \u001b[39m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1112\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[39m=\u001b[39m [], []\n",
      "File \u001b[0;32m~/snn-event-vpr/src/VPRNetwork.py:30\u001b[0m, in \u001b[0;36mVPRNetwork.forward\u001b[0;34m(self, spike)\u001b[0m\n\u001b[1;32m     28\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mforward\u001b[39m(\u001b[39mself\u001b[39m, spike):\n\u001b[1;32m     29\u001b[0m     \u001b[39mfor\u001b[39;00m block \u001b[39min\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mblocks:\n\u001b[0;32m---> 30\u001b[0m         spike \u001b[39m=\u001b[39m block(spike)\n\u001b[1;32m     31\u001b[0m     \u001b[39mreturn\u001b[39;00m spike\n",
      "File \u001b[0;32m~/mambaforge/envs/lavaenv/lib/python3.10/site-packages/torch/nn/modules/module.py:1110\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1106\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1107\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1108\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1109\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1110\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39;49m\u001b[39minput\u001b[39;49m, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m   1111\u001b[0m \u001b[39m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1112\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[39m=\u001b[39m [], []\n",
      "File \u001b[0;32m~/mambaforge/envs/lavaenv/lib/python3.10/site-packages/lava/lib/dl/slayer/block/base.py:507\u001b[0m, in \u001b[0;36mAbstractDense.forward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m    504\u001b[0m     \u001b[39melse\u001b[39;00m:\n\u001b[1;32m    505\u001b[0m         \u001b[39mself\u001b[39m\u001b[39m.\u001b[39msynapse\u001b[39m.\u001b[39mweight\u001b[39m.\u001b[39mdata \u001b[39m*\u001b[39m\u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mmask\n\u001b[0;32m--> 507\u001b[0m z \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49msynapse(x)\n\u001b[1;32m    508\u001b[0m x \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mneuron(z)\n\u001b[1;32m    509\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdelay_shift \u001b[39mis\u001b[39;00m \u001b[39mTrue\u001b[39;00m:\n",
      "File \u001b[0;32m~/mambaforge/envs/lavaenv/lib/python3.10/site-packages/torch/nn/modules/module.py:1128\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1125\u001b[0m     bw_hook \u001b[39m=\u001b[39m hooks\u001b[39m.\u001b[39mBackwardHook(\u001b[39mself\u001b[39m, full_backward_hooks)\n\u001b[1;32m   1126\u001b[0m     \u001b[39minput\u001b[39m \u001b[39m=\u001b[39m bw_hook\u001b[39m.\u001b[39msetup_input_hook(\u001b[39minput\u001b[39m)\n\u001b[0;32m-> 1128\u001b[0m result \u001b[39m=\u001b[39m forward_call(\u001b[39m*\u001b[39;49m\u001b[39minput\u001b[39;49m, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m   1129\u001b[0m \u001b[39mif\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks:\n\u001b[1;32m   1130\u001b[0m     \u001b[39mfor\u001b[39;00m hook \u001b[39min\u001b[39;00m (\u001b[39m*\u001b[39m_global_forward_hooks\u001b[39m.\u001b[39mvalues(), \u001b[39m*\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks\u001b[39m.\u001b[39mvalues()):\n",
      "File \u001b[0;32m~/mambaforge/envs/lavaenv/lib/python3.10/site-packages/lava/lib/dl/slayer/synapse/layer.py:166\u001b[0m, in \u001b[0;36mDense.forward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    164\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mlen\u001b[39m(\u001b[39minput\u001b[39m\u001b[39m.\u001b[39mshape) \u001b[39m==\u001b[39m \u001b[39m3\u001b[39m:\n\u001b[1;32m    165\u001b[0m     old_shape \u001b[39m=\u001b[39m \u001b[39minput\u001b[39m\u001b[39m.\u001b[39mshape\n\u001b[0;32m--> 166\u001b[0m     \u001b[39mreturn\u001b[39;00m F\u001b[39m.\u001b[39;49mconv3d(  \u001b[39m# bias does not need pre_hook_fx. Its disabled\u001b[39;49;00m\n\u001b[1;32m    167\u001b[0m         \u001b[39minput\u001b[39;49m\u001b[39m.\u001b[39;49mreshape(old_shape[\u001b[39m0\u001b[39;49m], \u001b[39m-\u001b[39;49m\u001b[39m1\u001b[39;49m, \u001b[39m1\u001b[39;49m, \u001b[39m1\u001b[39;49m, old_shape[\u001b[39m-\u001b[39;49m\u001b[39m1\u001b[39;49m]),\n\u001b[1;32m    168\u001b[0m         weight, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mbias,\n\u001b[1;32m    169\u001b[0m         \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mstride, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mpadding, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mdilation, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mgroups,\n\u001b[1;32m    170\u001b[0m     )\u001b[39m.\u001b[39mreshape(old_shape[\u001b[39m0\u001b[39m], \u001b[39m-\u001b[39m\u001b[39m1\u001b[39m, old_shape[\u001b[39m-\u001b[39m\u001b[39m1\u001b[39m])\n\u001b[1;32m    171\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m    172\u001b[0m     \u001b[39mreturn\u001b[39;00m F\u001b[39m.\u001b[39mconv3d(\n\u001b[1;32m    173\u001b[0m         \u001b[39minput\u001b[39m, weight, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mbias,\n\u001b[1;32m    174\u001b[0m         \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mstride, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mpadding, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdilation, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mgroups,\n\u001b[1;32m    175\u001b[0m     )\n",
      "\u001b[0;31mRuntimeError\u001b[0m: CUDA out of memory. Tried to allocate 40.00 MiB (GPU 0; 23.70 GiB total capacity; 195.51 MiB already allocated; 8.00 MiB free; 200.00 MiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF"
     ]
    }
   ],
   "source": [
    "# Define an optimiser \n",
    "optimizer = torch.optim.Adam(net.parameters(), lr=0.001)\n",
    "\n",
    "# Training the network\n",
    "error = slayer.loss.SpikeRate(true_rate=0.2, false_rate=0.03, reduction='sum').to(device)\n",
    "\n",
    "# Create a training assistant object\n",
    "stats = slayer.utils.LearningStats()\n",
    "assistant = slayer.utils.Assistant(net, error, optimizer, stats, classifier=slayer.classifier.Rate.predict)\n",
    "\n",
    "\n",
    "if redo_plot:\n",
    "    for i, (input, label) in enumerate(train_loader): # training loop\n",
    "        output = assistant.train(input, label)\n",
    "\n",
    "else: \n",
    "    for epoch in range(epochs):\n",
    "\n",
    "        for i, (input, label) in enumerate(train_loader): # training loop\n",
    "            output = assistant.train(input, label)\n",
    "        print(f'\\r[Epoch {epoch:2d}/{epochs}] {stats}', end='')\n",
    "\n",
    "        for i, (input, label) in enumerate(test_loader): # training loop\n",
    "            output = assistant.test(input, label)\n",
    "        print(f'\\r[Epoch {epoch:2d}/{epochs}] {stats}', end='')\n",
    "\n",
    "        if epoch%20 == 19: # cleanup display\n",
    "            print('\\r', ' '*len(f'\\r[Epoch {epoch:2d}/{epochs}] {stats}'))\n",
    "            stats_str = str(stats).replace(\"| \", \"\\n\")\n",
    "            print(f'[Epoch {epoch:2d}/{epochs}]\\n{stats_str}')\n",
    "\n",
    "        if stats.testing.best_accuracy:\n",
    "            torch.save(net.state_dict(), trained_folder + '/network.pt')\n",
    "        stats.update()\n",
    "        stats.save(trained_folder + '/')\n",
    "        net.grad_flow(trained_folder + '/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(22, 22)\n"
     ]
    }
   ],
   "source": [
    "# import the best network during training \n",
    "net.load_state_dict(torch.load(trained_folder + '/network.pt'))\n",
    "net.export_hdf5(trained_folder + '/network.net')\n",
    "\n",
    "# Get the output for the input to each place\n",
    "test_loader2  = DataLoader(dataset=testing_set , batch_size=batch_size, shuffle=False)\n",
    "rate = []\n",
    "labels = []\n",
    "for i, (input, label) in enumerate(test_loader2):\n",
    "    output = net(input.to(device)) # Get network output\n",
    "    #guesses = assistant.classifier(output).cpu().data.numpy() # get the predictions \n",
    "    rate.extend(Rate.rate(output).cpu().data.numpy()) # Get the firing rates for each place \n",
    "    labels.extend(label.cpu().data.numpy()) # Get place labels\n",
    "\n",
    "\n",
    "# # Get rates in percentages of total\n",
    "# for i in range(num_places):\n",
    "#     sum = np.sum(rate[i])\n",
    "#     if sum != 0:\n",
    "#         rate[i] = np.divide(rate[i],sum)\n",
    "\n",
    "# Make confusion matrix annotations\n",
    "accuracy = 0\n",
    "matches = []\n",
    "annotations = [['' for i in range(num_places)] for j in range(num_places)]\n",
    "for qryIndex in range(num_places):\n",
    "    max_idx = np.argmax(rate[qryIndex])\n",
    "    matches.append(max_idx)\n",
    "    annotations[max_idx][qryIndex] = 'x'\n",
    "    if max_idx ==qryIndex:\n",
    "        accuracy += 1\n",
    "\n",
    "\n",
    "#--------------- Apply a sequencer ------------------#\n",
    "I = np.identity(sequence_length)\n",
    "conv = signal.convolve2d(rate, I, mode='same')\n",
    "print(np.shape(conv))\n",
    "\n",
    "# Make confusion matrix annotations\n",
    "accuracy_s = 0\n",
    "matches_with_seq = []\n",
    "annotations_s = [['' for i in range(num_places)] for j in range(num_places)]\n",
    "for qryIndex in range(num_places):\n",
    "    max_idx = np.argmax(conv[qryIndex])\n",
    "    matches_with_seq.append(max_idx)\n",
    "    annotations_s[max_idx][qryIndex] = 'x'\n",
    "    if max_idx == qryIndex:\n",
    "        accuracy_s += 1\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "help\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 1296x288 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 1296x288 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "\n",
    "#--------------- Save Results ------------------#\n",
    "\n",
    "# Make new folder for results\n",
    "from tracemalloc import start\n",
    "from plotting import plot_gps\n",
    "\n",
    "\n",
    "time_stamp = datetime.now().strftime('%Y-%m-%d_%H-%M-%S')\n",
    "results_path = \"./../results/\" + time_stamp\n",
    "os.mkdir(results_path)\n",
    "\n",
    "\n",
    "# Save query and match images \n",
    "images_path = results_path + \"/matched_images\"\n",
    "images_path_seq = results_path + \"/matched_images_seq\"\n",
    "os.mkdir(images_path)\n",
    "os.mkdir(images_path_seq)\n",
    "\n",
    "print('help')\n",
    "plot_match_images(images_path + \"/\", matches, training_set.place_images, testing_set.place_images)\n",
    "plot_match_images(images_path_seq + \"/\", matches_with_seq, training_set.place_images, testing_set.place_images)\n",
    "\n",
    "# Save the confusion matrices\n",
    "confusion_path = results_path + \"/confusion_matrices\"\n",
    "os.mkdir(confusion_path)\n",
    "rate = transpose(rate)\n",
    "conv = transpose(conv)\n",
    "output_path = confusion_path + \"/confusion_matrix\" \n",
    "output_path_s = confusion_path + \"/confusion_matrix_seq\" \n",
    "plot_confusion_matrix(rate, labels, annotations, output_path, vmin, vmax)\n",
    "plot_confusion_matrix(conv, labels, annotations_s, output_path_s, vmin, vmax)\n",
    "\n",
    "# Save GPS map'\n",
    "# gps_path = results_path + \"/gps_locations\"\n",
    "# plot_gps(gps_path, training_set.place_locations, testing_set.place_locations)\n",
    "\n",
    "# Save test settings and accuracy\n",
    "accuracy = accuracy/num_places\n",
    "accuracy_s = accuracy_s/num_places\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The accuracy of the network is: 0.8636363636363636\n",
      "The accuracy with a sequencer is: 1.0\n"
     ]
    }
   ],
   "source": [
    "\n",
    "log_path = results_path + \"/log.txt\"\n",
    "\n",
    "if use_pre_synced_times:\n",
    "    log_string  = \"\"\"\n",
    "    ---- DATA SETTINGS ---- \n",
    "    Training datasets = {}\n",
    "    Testing datasets = {} \n",
    "    # Places = {}\n",
    "    Using presynced times = True\n",
    "    Place duration = {} [s]\n",
    "    Samples per second = {} \n",
    "    Max spikes per sample = {}\n",
    "    Incorporate speed = {}\n",
    "    ---- NETWORK SETTINGS ---- \n",
    "    Input size = {}x{} \n",
    "    Threshold = {}\n",
    "    ---- TRAINING SETTINGS ---- \n",
    "    Epochs = {}\n",
    "    Batch size = {}\n",
    "    ---- SEQUENCER SETTINGS ----\n",
    "    Sequence lengtth = {} \n",
    "    ---- RESULTS ----\n",
    "    Accuracy = {}\n",
    "    Accuracy (sequencer) = {}\n",
    "    \"\"\".format(train_name,test_name, num_places, place_duration,\n",
    "                    samples_per_sec,max_spikes, incorporate_speed, input_size,input_size,threshold,epochs,\n",
    "                    batch_size,sequence_length,accuracy,accuracy_s)\n",
    "\n",
    "else: \n",
    "    log_string  = \"\"\"\n",
    "    ---- DATA SETTINGS ---- \n",
    "    Training datasets = {}\n",
    "    Testing datasets = {} \n",
    "    # Places = {}\n",
    "    Start time = {} [s]\n",
    "    Place gap = {} [s]\n",
    "    Place duration = {} [s]\n",
    "    Samples per second = {} \n",
    "    Max spikes per sample = {}\n",
    "    Incorporate speed = {}\n",
    "    ---- NETWORK SETTINGS ---- \n",
    "    Input size = {}x{} \n",
    "    Threshold = {}\n",
    "    ---- TRAINING SETTINGS ---- \n",
    "    Epochs = {}\n",
    "    Batch size = {}\n",
    "    ---- SEQUENCER SETTINGS ----\n",
    "    Sequence lengtth = {} \n",
    "    ---- RESULTS ----\n",
    "    Accuracy = {}\n",
    "    Accuracy (sequencer) = {}\n",
    "    \"\"\".format(train_name,test_name,num_places,start_time,place_gap,place_duration,\n",
    "                    samples_per_sec,max_spikes, incorporate_speed, input_size,input_size,threshold,epochs,\n",
    "                    batch_size,sequence_length,accuracy,accuracy_s)\n",
    "f = open(log_path,'w')\n",
    "f.write(log_string)\n",
    "f.close()\n",
    "\n",
    "print(\"The accuracy of the network is: \" + str(accuracy))\n",
    "print(\"The accuracy with a sequencer is: \" + str(accuracy_s))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.4 ('lavaenv')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "63e713066215dbc07efbeb034515a5b964b6ad27977c03151c829f7f04a8001d"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
